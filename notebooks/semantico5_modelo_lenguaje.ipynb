{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "NLP-2",
      "dashboards": [],
      "language": "python",
      "widgets": {},
      "notebookOrigID": 708434827944260
    },
    "colab": {
      "name": "semantico5_modelo_lenguaje.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ab5f4dac-4f82-4ded-8d29-14125218f3fb"
        },
        "id": "im74RVioFa0y"
      },
      "source": [
        "#Generación de lenguaje natural\n",
        "El objetivo de este notebook es mostrar mecanismos básicos de creación de un modelo completo del lenguaje natural que ayude a predecir las siguientes palabras, y de ese modo, generar texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fb51bcf0-1037-438b-9c17-ed41a60546c4"
        },
        "id": "hhJ3qzsXFa08"
      },
      "source": [
        "import sklearn\n",
        "import os, re, string, collections, random\n",
        "import spacy\n",
        "import nltk\n",
        "import numpy, matplotlib\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6b8bc6df-9ebc-4318-b19e-54fb802007e7"
        },
        "id": "qzG9AtN9Fa0_"
      },
      "source": [
        "Creemos un corpus de NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBkt3OdhG9rs",
        "outputId": "4a10ef92-c94d-4c88-8ebc-f7e15e0e8d39"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "df3ede2a-3ef2-4c0f-937b-bf709e199015"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtUjFvAPFa1A",
        "outputId": "750a3153-bdff-4e52-9c41-65ae7c1103b0"
      },
      "source": [
        "from nltk.corpus import PlaintextCorpusReader\n",
        "corpus_root=\"/content/drive/My Drive/corpus/libros\"\n",
        "corpusesp=PlaintextCorpusReader(corpus_root,\".*\", encoding=\"UTF-8\")\n",
        "\"\"\"para ver que archivos quedaron\"\"\"\n",
        "corpusesp.fileids()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['candido-de-voltaire.txt',\n",
              " 'cuentos_allan_poe.txt',\n",
              " 'el-buscon.txt',\n",
              " 'elquijote.txt',\n",
              " 'fabulas_samaniego.txt',\n",
              " 'juan_tenorio.txt',\n",
              " 'libro_cocina.txt',\n",
              " 'milyuna_t1.txt',\n",
              " 'nuevo_testamento_valera.txt',\n",
              " 'obras-escogidas_becquer.txt',\n",
              " 'odisea.txt',\n",
              " 'relacionhistoricasucesosdetupacamaru.txt',\n",
              " 'tradiciones_peruanas_ricardo_palma.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "28f87a84-f695-4a18-8614-97f23e5e19ee"
        },
        "id": "t_drz8WoFa1C"
      },
      "source": [
        "Y creemos el corpus en una lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d1105373-a415-4287-a1a1-04371fed9e8c"
        },
        "id": "_LLZ1JaxFa1D"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/corpus/libros\")\n",
        "documents = []\n",
        "for f in os.listdir():\n",
        "    if f[-4:] == '.txt':\n",
        "        documents.append(f[:-4])\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9c046034-0da4-4b4d-99c4-851b1012a22a"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXMQjFx1Fa1E",
        "outputId": "a369a77d-e721-41db-88ed-920b6703a1a6"
      },
      "source": [
        "documents"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['milyuna_t1',\n",
              " 'relacionhistoricasucesosdetupacamaru',\n",
              " 'tradiciones_peruanas_ricardo_palma',\n",
              " 'elquijote',\n",
              " 'cuentos_allan_poe',\n",
              " 'juan_tenorio',\n",
              " 'libro_cocina',\n",
              " 'obras-escogidas_becquer',\n",
              " 'candido-de-voltaire',\n",
              " 'el-buscon',\n",
              " 'nuevo_testamento_valera',\n",
              " 'fabulas_samaniego',\n",
              " 'odisea']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "794e764d-6c62-4434-ad5e-827cd8cbfc00"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-iGP7OFa1F",
        "outputId": "7af95c33-af35-48d0-f515-0ba0862d7230"
      },
      "source": [
        "len(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6f0f3381-a4da-41c3-93ef-835b4b5220e6"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkxUNHHtFa1H",
        "outputId": "98ec0a5e-3e2c-4a6b-ef27-f761b79bec7f"
      },
      "source": [
        "contents = []\n",
        "for document in documents:\n",
        "    with open(document+'.txt', 'r', encoding=\"UTF-8\") as f:\n",
        "        contents.append(f.read())\n",
        "len(contents)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "43c2396c-55a5-4389-8f35-78510ef7e9f8"
        },
        "id": "uEUVEmD8Fa1J"
      },
      "source": [
        "for i in range(0,len(contents)):\n",
        "    inicio=contents[i].find(\"EBOOK\")\n",
        "    final=contents[i].find(\"END OF\")\n",
        "    contents[i]=contents[i][inicio:final]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "70088e1f-d150-445d-849e-1f8896b6853a"
        },
        "id": "OP7dxcLjFa1K"
      },
      "source": [
        "for i in range(len(contents)):\n",
        "    contents[i] = re.sub(\"\\\"\",\" \",contents[i])\n",
        "    contents[i] = re.sub (\"\\n|\\t\",\" \",contents[i])\n",
        "    contents[i]=contents[i].lower()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "538eaa1f-a030-4c96-9c02-1a89a7906441"
        },
        "id": "gy30Af0JFa1f"
      },
      "source": [
        "\n",
        "Los generadores de lenguaje natural tiene como objetivo predecir, dado un texto anterior, el texto que viene después. Si bien su aplicación inicial es simplemente ser predictores de texto, se han convertido en herramienta fundamental para las aplicaciones modernas de NLP, pues generan una representación del lenguaje. Miremos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "1052ac0c-3268-48b7-9b1f-206751ee9bd6"
        },
        "id": "-7VpS7DhFa1f"
      },
      "source": [
        "import nltk \n",
        "from nltk import bigrams, trigrams\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "       \n",
        "candido=corpusesp.words(\"candido-de-voltaire.txt\")\n",
        "\n",
        "pares=nltk.bigrams(candido)\n",
        "generator=nltk.ConditionalFreqDist(pares)\n",
        "\n",
        "##de pronto cambiar a 3 para hablar de predictor de texto\"\n",
        "def predictor(dist,palabra,num):\n",
        "    for i in range(num):\n",
        "        print(palabra,end=\" \")\n",
        "        palabra=dist[palabra].max()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e80a0294-6541-43c9-88ba-cf2e3b8a2c3d"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ddvtwbGFa1f",
        "outputId": "8218037a-83d6-4b38-ae16-e37ed19c562f"
      },
      "source": [
        "#probar vieja, hizo, real#        \n",
        "predictor(generator,\"vieja\",12)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vieja , y el señor baron , y el señor baron , "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e2c5d9a2-6004-43e3-bd9e-86dc97dd9395"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb4E8a4mFa1f",
        "outputId": "07345041-d81e-4a28-ec8b-613142b590b5"
      },
      "source": [
        "generator[\"señor\"]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'baron': 12, ',': 7, 'inquisidor': 4, 'abate': 4, 'Pococurante': 4, 'Panglós': 3, 'gobernador': 3, 'Martin': 3, 'de': 2, 'Don': 2, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTyeV1KzyYl1"
      },
      "source": [
        "Ahora vamos a hacer un generador más complejo (basado en un ejemplo visto en analyticsvidtha). Creo un contenedor de modelo:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rng5gNaHEuS2",
        "outputId": "1a15168b-b50a-46b6-8760-8b548ea31ba7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['milyuna_t1',\n",
              " 'relacionhistoricasucesosdetupacamaru',\n",
              " 'tradiciones_peruanas_ricardo_palma',\n",
              " 'elquijote',\n",
              " 'cuentos_allan_poe',\n",
              " 'juan_tenorio',\n",
              " 'libro_cocina',\n",
              " 'obras-escogidas_becquer',\n",
              " 'candido-de-voltaire',\n",
              " 'el-buscon',\n",
              " 'nuevo_testamento_valera',\n",
              " 'fabulas_samaniego',\n",
              " 'odisea']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fbTPyKfyPh1",
        "outputId": "708ccbd1-429b-4c3f-fbdd-e43edcd28168"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "prueba3=nltk.word_tokenize(contents[3])\n",
        "prueba3[1:100]\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['don',\n",
              " 'quijote',\n",
              " '*',\n",
              " '*',\n",
              " '*',\n",
              " 'produced',\n",
              " 'by',\n",
              " 'an',\n",
              " 'anonymous',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'volunteer',\n",
              " '.',\n",
              " 'text',\n",
              " 'file',\n",
              " 'corrections',\n",
              " 'and',\n",
              " 'new',\n",
              " 'html',\n",
              " 'file',\n",
              " 'by',\n",
              " 'joaquin',\n",
              " 'cuenca',\n",
              " 'abela',\n",
              " '.',\n",
              " 'el',\n",
              " 'ingenioso',\n",
              " 'hidalgo',\n",
              " 'don',\n",
              " 'quijote',\n",
              " 'de',\n",
              " 'la',\n",
              " 'mancha',\n",
              " 'tasa',\n",
              " 'yo',\n",
              " ',',\n",
              " 'juan',\n",
              " 'gallo',\n",
              " 'de',\n",
              " 'andrada',\n",
              " ',',\n",
              " 'escribano',\n",
              " 'de',\n",
              " 'cámara',\n",
              " 'del',\n",
              " 'rey',\n",
              " 'nuestro',\n",
              " 'señor',\n",
              " ',',\n",
              " 'de',\n",
              " 'los',\n",
              " 'que',\n",
              " 'residen',\n",
              " 'en',\n",
              " 'su',\n",
              " 'consejo',\n",
              " ',',\n",
              " 'certifico',\n",
              " 'y',\n",
              " 'doy',\n",
              " 'fe',\n",
              " 'que',\n",
              " ',',\n",
              " 'habiendo',\n",
              " 'visto',\n",
              " 'por',\n",
              " 'los',\n",
              " 'señores',\n",
              " 'dél',\n",
              " 'un',\n",
              " 'libro',\n",
              " 'intitulado',\n",
              " 'el',\n",
              " 'ingenioso',\n",
              " 'hidalgo',\n",
              " 'de',\n",
              " 'la',\n",
              " 'mancha',\n",
              " ',',\n",
              " 'compuesto',\n",
              " 'por',\n",
              " 'miguel',\n",
              " 'de',\n",
              " 'cervantes',\n",
              " 'saavedra',\n",
              " ',',\n",
              " 'tasaron',\n",
              " 'cada',\n",
              " 'pliego',\n",
              " 'del',\n",
              " 'dicho',\n",
              " 'libro',\n",
              " 'a',\n",
              " 'tres',\n",
              " 'maravedís',\n",
              " 'y',\n",
              " 'medio',\n",
              " ';',\n",
              " 'el']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfZTy_OZykFU"
      },
      "source": [
        "Cuento las frecuencias de co-ocurrencias en trigramas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJQhRamiytcw"
      },
      "source": [
        "   for w1, w2, w3 in trigrams(prueba3, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JunWnIEWyzV4"
      },
      "source": [
        "Transformo en probabilidades"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snSa741xy1zT",
        "outputId": "d1074bdf-f7f6-4199-f8a6-0622f75a1f78"
      },
      "source": [
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count\n",
        "\n",
        "dict(model[\"el\",\"caballo\"])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'de': 0.2608695652173913,\n",
              " 'al': 0.043478260869565216,\n",
              " 'a': 0.043478260869565216,\n",
              " 'no': 0.08695652173913043,\n",
              " 'y': 0.043478260869565216,\n",
              " 'pegaso': 0.043478260869565216,\n",
              " ',': 0.08695652173913043,\n",
              " 'quedó': 0.043478260869565216,\n",
              " 'en': 0.08695652173913043,\n",
              " 'relinche': 0.043478260869565216,\n",
              " 'está': 0.043478260869565216,\n",
              " 'se': 0.043478260869565216,\n",
              " 'lleno': 0.043478260869565216,\n",
              " 'mostraba': 0.043478260869565216,\n",
              " 'con': 0.043478260869565216}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmS2P7NYy6mI"
      },
      "source": [
        "Primer modelo: con palabras máximas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNXEMdEmy9CA",
        "outputId": "bb764abf-7d91-4dca-e3f8-d6f73cb78cfa"
      },
      "source": [
        "def mln(pal1, pal2, num=10):\n",
        "    for i in range(num):\n",
        "        base=dict(model[pal1,pal2])\n",
        "        print(pal1, end=\" \")\n",
        "        pal1=pal2\n",
        "        pal2=max(base,key=base.get)\n",
        "\n",
        "\n",
        "mln(\"el\",\"caballo\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el caballo de madera , sobre todo , y , "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qEElO1zzBEE",
        "outputId": "456b35d4-43c2-4573-b376-7791fdac6d7f"
      },
      "source": [
        "mln(\"don\", \"quijote\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "don quijote , y , en el mundo , y "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR_D-p4ZzCp6"
      },
      "source": [
        "Se crea un problema debido a los bucles o ciclos. Es mejor escoger una palabra aleatoria al menos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2B1yzjFzay2",
        "outputId": "7c048a89-ab62-4f79-8873-be401f481b1e"
      },
      "source": [
        "text = [\"el\", \"caballo\"]\n",
        "\n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "  # select a random probability threshold  \n",
        "  r = random.random()\n",
        "  accumulator = .0\n",
        "\n",
        "  for word in model[tuple(text[-2:])].keys():\n",
        "      accumulator += model[tuple(text[-2:])][word]\n",
        "      # select words that are above the probability threshold\n",
        "      if accumulator >= r:\n",
        "          text.append(word)\n",
        "          break\n",
        "\n",
        "  if text[-2:] == [None, None]:\n",
        "      sentence_finished = True\n",
        "\n",
        "  if len(text)==100:\n",
        "      sentence_finished = True\n",
        " \n",
        "print (' '.join([t for t in text if t]))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el caballo de madera que los venció sola una cosa quiero castigar a este salteador de caminos . -todo eso es así -dijo don quijote- . ven acá , digo que no debe de ser algún grandísimo bellaco , con todo esto , quiso hacer tirteafuera de la que será . encomiéndeme a sanchica , su primer intento , y aquella gallardía que conviene en caso de duda , le dijo : `` ámexi , cristiano , siendo forzoso que pregunten muchos : `` ninguno responda ; porque , siendo a todas partes , y liólas sobre rocinante , ni\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfibvSpzzhdH"
      },
      "source": [
        "O aun mejor, con palabras proporcionales a su probabilidad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "bFXmLnyXzks3",
        "outputId": "0004bba8-af17-449e-e350-16b775cdb409"
      },
      "source": [
        "text3=\"el\"\n",
        "text4=\"caballo\"\n",
        "nueva=[text3,text4]\n",
        "i=0\n",
        "   \n",
        "while i<100:\n",
        "    temporal=random.choices(population=list(model[text3,text4].keys()),weights=list(model[text3,text4].values()),k=1)\n",
        "    nueva.append(temporal[0])\n",
        "    text3=text4\n",
        "    text4=temporal[0]    \n",
        "    i=i+1\n",
        "    \n",
        "totalcreado=\" \".join(nueva)\n",
        "totalcreado    \n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'el caballo no se sabe que la tengo y tres , y tras todos éstos parece mejor un poeta , y le paseó todo , que es de moro -respondió don quijote- : vete adonde quisieres , que con lo que tan aborrecida tenía . otros las cuenten y las demás cosas que en este gobierno y sin segundo , por más señas , que de cuando en semejantes causas . -por esta figura que anda por esta vez se conoció haber corrido algo , por venir , ni hemos decantado de donde arguyo yo que se llamaba torralba , la túnica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}