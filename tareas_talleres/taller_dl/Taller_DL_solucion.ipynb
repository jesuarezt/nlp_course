{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:01:35.341404Z",
     "start_time": "2022-02-28T12:01:34.914124Z"
    },
    "id": "u0ukr7quvrMx",
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Escribe código que cree un `torch.tensor` con los siguientes contenidos:\n",
    "$\\begin{bmatrix} 1 & 2.2 & 9.6 \\\\ 4 & -7.2 & 6.3 \\end{bmatrix}$\n",
    "\n",
    "Ahora calcule el promedio de cada fila (`.mean()`) y cada columna.\n",
    "\n",
    "¿Cuál es la forma de los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.2000,  9.6000],\n",
       "        [ 4.0000, -7.2000,  6.3000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solución\n",
    "t1 = torch.tensor([1,2.2,9.6,4,-7.2,6.3])\n",
    "t1 = t1.reshape(2,3)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector media por columna tensor([ 2.5000, -2.5000,  7.9500])\n",
      "Vector media por filas tensor([4.2667, 1.0333])\n"
     ]
    }
   ],
   "source": [
    "mean_col = t1.mean(dim=0)\n",
    "print(f'Vector media por columna {mean_col}')\n",
    "mean_row = t1.mean(dim=1)\n",
    "print(f'Vector media por filas {mean_row}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Escribe código que cree un `torch.tensor` con los siguientes contenidos:\n",
    "$\\begin{bmatrix} 1 & 2.2 & 9.6 \\\\ 4 & -7.2 & 6.3 \\end{bmatrix}$\n",
    "\n",
    "¿Cómo se obtiene la primera columna? ¿La primera fila?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.2000,  9.6000],\n",
       "        [ 4.0000, -7.2000,  6.3000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([1,2.2,9.6,4,-7.2,6.3])\n",
    "t2 = t2.reshape(2,3)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primera columna\n",
      "tensor([1., 4.])\n",
      "primera fila\n",
      "tensor([1.0000, 2.2000, 9.6000])\n"
     ]
    }
   ],
   "source": [
    "print('primera columna')\n",
    "print(t2[:,0])\n",
    "print('primera fila')\n",
    "print(t2[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Cree una función vectorial (no lineal) en función de dos o tres vectores, determine sus derivadas respecto a cada componente de los vectores, para valores particulares, usando pytorch. Compruebe el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(50.), tensor(1.), tensor(1.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partial_derivates(f): \n",
    "    \"\"\"_summary_\n",
    "    Args:\n",
    "        f (fuction): _description_: vectorial function\n",
    "    \"\"\"\n",
    "    \n",
    "    #exec('f = lambda x,y,z: 5*x**2 + y + z')\n",
    "    f.backward()\n",
    "\n",
    "    return (x.grad, y.grad, z.grad)\n",
    "\n",
    "x = torch.tensor(float(5), requires_grad=True)\n",
    "y = torch.tensor(float(7), requires_grad=True)\n",
    "z = torch.tensor(float(1), requires_grad=True)\n",
    "    \n",
    "partial_derivates(  f = 5*x**2 + y + z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.), tensor(5.), tensor(35.))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(float(5), requires_grad=True)\n",
    "y = torch.tensor(float(7), requires_grad=True)\n",
    "z = torch.tensor(float(1), requires_grad=True)\n",
    "\n",
    "partial_derivates(f = x*y*z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "Use el dataset de `progressive-tweet-sentiment.csv` (el del taller 1), para producir una representación de vectores usando word2vec (máximo 50 vectores). Divida en un conjunto de entrenamiento y otro de prueba. A continuación, realice una clasificación de los tweets con un MLP (multilayer perceptron) de una capa oculta (tendrá que probar cuantas neuronas ocultas), usando como variables la media de los vectores de las palabras de cada tweet. Debe utilizar pytorch. Grafique el loss y el accuracy, tanto para el entrenamiento como para la validación. Escoja el mejor modelo probando con un buen número de epochs (use un learning rate de 0.1 o 0.01).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias\n",
    "import pandas as pd\n",
    "import re\n",
    "#tokenizar con nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#copy\n",
    "from copy import deepcopy\n",
    "\n",
    "#construccion de la red neuronal multicapa (Multilayer perceptron)\n",
    "#importar librerias\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# para iterar combinaciones\n",
    "from itertools import product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>Thank you for another day of life Lord. #Chris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@rosaryrevival Lovely to use Glorious Mysterie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@Niall250 good thing is that #DUP have consist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>So, you tell me... is murder okay if the victi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@HillaryClinton Don't you mean to say (all chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     target                                              tweet\n",
       "0  Legalization of Abortion  Thank you for another day of life Lord. #Chris...\n",
       "1  Legalization of Abortion  @rosaryrevival Lovely to use Glorious Mysterie...\n",
       "2  Legalization of Abortion  @Niall250 good thing is that #DUP have consist...\n",
       "3  Legalization of Abortion  So, you tell me... is murder okay if the victi...\n",
       "4  Legalization of Abortion  @HillaryClinton Don't you mean to say (all chi..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/progressive-tweet-sentiment.csv', encoding='latin-1')\n",
    "df = df[[\"target\", \"tweet\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jessuarez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    thank another day life lord christian catholic...\n",
       "1    lovely use glorious mysteries eastertide mark ...\n",
       "2    good thing dup consistently said murder wrong ...\n",
       "3            tell murder okay victim mentally disabled\n",
       "4    dont mean say children deserve chances except ...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpieza\n",
    "\n",
    "def limpieza(text):\n",
    "  text=re.sub(r'@_[A-Za-z0-9]+_','',text) #Remover @_menciones_\n",
    "  text=re.sub(r'@[A-Za-z0-9]+_[A-Za-z0-9]+','',text) #Remover @menciones_\n",
    "  text=re.sub(r'@[A-Za-z0-9]+','',text) #Remover @menciones\n",
    "  text=re.sub(r'https?:\\/\\/\\S+','',text) #Remover Hypervinculos\n",
    "  text=re.sub(r'RT[\\s]+','',text) #Remover Retweets\n",
    "  text=re.sub(r'[^\\w\\s]',\"\",text) #remover signos de puntuacion\n",
    "  text=re.sub(r'#[A-Za-z0-9]+','',text) #Remover \"#\"\n",
    "  text=re.sub(r'[0-9]','',text) #remover numeros\n",
    "  text=re.sub(r'[^\\w\\s]',\"\",text) #remover signos de puntuacion\n",
    "  text=re.sub(r'\\n|\\t',' ',text) #remover saltos de linea\n",
    "  text=re.sub(r'\\@',' ',text) #remover \"@\"\n",
    "  text=re.sub(r'[\\s]+',' ',text) #reemplazar espacios dobles por espacion sencillos\n",
    "  text=re.sub(r\"^[\\s]\",' ',text) #eliminar espacios al inicio de cada tweet\n",
    "  text=text.lower() #todo a minuscula\n",
    "  return text\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#limpieza inicial de los tweetseza)\n",
    "# Excluir stopwords\n",
    "df['text_clean']=df[\"tweet\"].apply(limpieza)\n",
    "df['text_clean'] = df[\"text_clean\"].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\n",
    "df['text_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jessuarez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# tokenizar\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "#tokenizar cada tweet eliminando stopwords\n",
    "listado=[]\n",
    "for i in range(len(df)):\n",
    "  aux=word_tokenize(df['text_clean'][i])\n",
    "  aux2=[]\n",
    "  for word in aux:\n",
    "    if word not in stop: \n",
    "      aux2.append(word)\n",
    "  listado.append(aux2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros del modelo word2vec \n",
    "\n",
    "vector_size = 50 # numero de elementos del vector que representa la palabra\n",
    "min_count =3 # Ignores all words with total frequency lower than this. \n",
    "workers = 5 # numero de cpu cores\n",
    "sg = 0 # 0: CBOW, 1: skip-gram\n",
    "window = 6 # Tamano de la ventana de contexto\n",
    "sample = 1e-3 # tasa de submuestreo para terminos frecuentes\n",
    "model = Word2Vec(listado, vector_size=vector_size,min_count=min_count, workers=workers,sg=sg,window=window,sample=sample, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/1h5_y8x165n9_dtqpqg0vsw07w60nb/T/ipykernel_2233/2160571216.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['vectors']=tweet_vector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tweet</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>Thank you for another day of life Lord. #Chris...</td>\n",
       "      <td>thank another day life lord christian catholic...</td>\n",
       "      <td>[-710.8521343231201, -5.7086110687255855, -7.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@rosaryrevival Lovely to use Glorious Mysterie...</td>\n",
       "      <td>lovely use glorious mysteries eastertide mark ...</td>\n",
       "      <td>[258.9428883361816, 1.2344049072265626, 1.6824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@Niall250 good thing is that #DUP have consist...</td>\n",
       "      <td>good thing dup consistently said murder wrong ...</td>\n",
       "      <td>[-3.891765289306641, 10.893544616699218, 73.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>So, you tell me... is murder okay if the victi...</td>\n",
       "      <td>tell murder okay victim mentally disabled</td>\n",
       "      <td>[0.20331680297851562, 18.243045349121093, 2.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legalization of Abortion</td>\n",
       "      <td>@HillaryClinton Don't you mean to say (all chi...</td>\n",
       "      <td>dont mean say children deserve chances except ...</td>\n",
       "      <td>[58.7990193939209, 15.21827392578125, -22.5602...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     target  \\\n",
       "0  Legalization of Abortion   \n",
       "1  Legalization of Abortion   \n",
       "2  Legalization of Abortion   \n",
       "3  Legalization of Abortion   \n",
       "4  Legalization of Abortion   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  Thank you for another day of life Lord. #Chris...   \n",
       "1  @rosaryrevival Lovely to use Glorious Mysterie...   \n",
       "2  @Niall250 good thing is that #DUP have consist...   \n",
       "3  So, you tell me... is murder okay if the victi...   \n",
       "4  @HillaryClinton Don't you mean to say (all chi...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  thank another day life lord christian catholic...   \n",
       "1  lovely use glorious mysteries eastertide mark ...   \n",
       "2  good thing dup consistently said murder wrong ...   \n",
       "3          tell murder okay victim mentally disabled   \n",
       "4  dont mean say children deserve chances except ...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-710.8521343231201, -5.7086110687255855, -7.3...  \n",
       "1  [258.9428883361816, 1.2344049072265626, 1.6824...  \n",
       "2  [-3.891765289306641, 10.893544616699218, 73.47...  \n",
       "3  [0.20331680297851562, 18.243045349121093, 2.25...  \n",
       "4  [58.7990193939209, 15.21827392578125, -22.5602...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#funcion para calcular el promedio de los vectores de cada token por tweet\n",
    "import numpy as np\n",
    "tweet_vector=[]\n",
    "for i in range(len(listado)):\n",
    "  v1=[0 for i in range(vector_size)]\n",
    "  for j in range(len(listado[i])):\n",
    "    if listado[i][j] in model.wv:\n",
    "      v2=model.wv.get_vector(listado[i][j])\n",
    "      v2=1/np.log(1+v2)\n",
    "      v1=[v1[k] + v2[k] for k in range(len(v1))]\n",
    "  v1=[v1[k]/len(v1) for k in range(len(v1))]\n",
    "  tweet_vector.append(v1)\n",
    "\n",
    "#tweet_vector\n",
    "\n",
    "df2=df[:]\n",
    "df2\n",
    "df2['vectors']=tweet_vector\n",
    "df2.head(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbV12-NsQqle",
    "outputId": "ab22560b-ff2d-4d07-f33b-f59c19660158"
   },
   "outputs": [],
   "source": [
    "# Estandarizando datos Para modelo\n",
    "df2 = df2.assign(total_sum = df2.vectors.apply( lambda x: sum(x)))\n",
    "\n",
    "#Eliminamos aquellos sin representación sparsing\n",
    "df2 = df2.loc[df2.total_sum != 0,:]\n",
    "\n",
    "# creando vector X \n",
    "X=list(df2.vectors)\n",
    "X= np.asarray(X)\n",
    "\n",
    "#Estandarizando\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando variable target numerica para la red\n",
    "df2 = df2.assign(target = pd.Categorical(df2.target))\n",
    "df2 = df2.assign(target_codes = df2.target.cat.codes)\n",
    "\n",
    "y = list(deepcopy( df2.target_codes))\n",
    "y= np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1153, 50)\n",
      "(1153,)\n"
     ]
    }
   ],
   "source": [
    "# validando dimensiones\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T0QwUm2rctS2"
   },
   "outputs": [],
   "source": [
    "def loss_acc_batch(x,y, model, DEVICE, loss_func, acc = None):\n",
    "    yp = model(x.to(DEVICE))\n",
    "    yt = y.to(DEVICE).long() # .long() porque espera un entero tipo long\n",
    "    loss = loss_func(yp, yt)\n",
    "    out = [loss, len(x)]\n",
    "    \n",
    "    if acc is not None:\n",
    "        y_pred = torch.argmax(model(x.to(DEVICE)), 1) \n",
    "        accuracy = (y_pred == yt).float().mean().item()\n",
    "        out.append(accuracy)#nar todas las palabras de nuestro vocabulario a un índice correspondiente. Podemos hacerlo de la siguiente\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "h64FEycoc0zn"
   },
   "outputs": [],
   "source": [
    "def train(model, train_dl,DEVICE, loss_func, opt, NUM_EPOCHS, valid_dl):\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs=[]\n",
    "    valid_accs=[]\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train() # importante para activar ciertas funciones como dropout, batchnormalization, etc.\n",
    "        losses = 0\n",
    "        nums = 0\n",
    "        train_acc=[]\n",
    "        for x, y in train_dl:\n",
    "            #loss, l = loss_acc_batch(x,y)\n",
    "            loss, l,acc = loss_acc_batch(x=x,y=y,model=model,loss_func=loss_func,DEVICE=DEVICE,acc=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            losses += loss.item() * l\n",
    "            nums += l\n",
    "            train_acc.append(acc)\n",
    "        train_loss = losses / nums\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        \n",
    "        model.eval()  #importante para desactivar ciertas funciones como dropout, batchnormalization, etc.\n",
    "        with torch.no_grad():\n",
    "            losses, nums, accs = zip(*[loss_acc_batch(x=xb, y=yb,loss_func=loss_func, model = model, DEVICE=DEVICE, acc=True) for xb, yb in valid_dl])\n",
    "        losses = [l.item() for l in losses]\n",
    "        valid_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        valid_acc = np.sum(np.multiply(accs,nums)) / np.sum(nums)\n",
    "        valid_accs.append(valid_acc)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch: {epoch}, train_loss: {train_loss:.4f} \\\n",
    "            valid_loss: {valid_loss:.4f}, valid_acc: {valid_acc:.4f}\")\n",
    "    \n",
    "    \n",
    "    return train_losses,train_accs,valid_losses,valid_accs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificando para validar diferentes EPOCAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_excercise(X, y, RANDOM_SEED=1, BATCH_SIZE=20, NUM_EPOCHS=100, lr=0.01, NUM_HIDDEN = 20, DEVICE = None, get_results =False):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    # Ajustando dataset para el modelo\n",
    "    ########################################################\n",
    "    torch.manual_seed(RANDOM_SEED); # configurar semilla\n",
    "\n",
    "    #separar en datos de test y de entrenamiento\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "\n",
    "    #convertir numpy arrays a tensores\n",
    "    X_train, y_train, X_valid, y_valid = map( lambda x: torch.tensor(x, dtype=torch.float32),\n",
    "                                            (X_train, y_train, X_valid, y_valid) )\n",
    "\n",
    "    #convertir a tensor dataset\n",
    "    train_ds = TensorDataset(X_train, y_train.long())\n",
    "    valid_ds = TensorDataset(X_valid, y_valid.long())\n",
    "\n",
    "    #convertir a dataloader\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size = 2*BATCH_SIZE)\n",
    "\n",
    "\n",
    "    print('tam muestra de entrenamiento')\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    ########################################################\n",
    "    # Definiendo modelo\n",
    "    ########################################################\n",
    "    num_features = X.shape[1]\n",
    "    num_hidden = NUM_HIDDEN\n",
    "    num_classes = len(torch.unique(y_train))\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(num_features,num_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hidden, num_classes)\n",
    "    )\n",
    "\n",
    "    loss_func = F.cross_entropy\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    opt = optim.SGD(model.parameters(),lr = lr)\n",
    "\n",
    "    train_losses,train_accs,valid_losses,valid_accs=train(model=model,train_dl=train_dl, valid_dl = valid_dl,\n",
    "                                                            DEVICE=DEVICE, loss_func=loss_func,\n",
    "                                                            opt = opt, NUM_EPOCHS=NUM_EPOCHS)\n",
    "\n",
    "\n",
    "    if get_results:\n",
    "        return train_losses,train_accs,valid_losses,valid_accs\n",
    "    else:\n",
    "        return valid_accs[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ = {'learning_rate': [0.1, 0.01],\n",
    "            'NUM_HIDDEN': [10,50,100],\n",
    "            'epochs': [10,50, 75,100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3853             valid_loss: 1.3893, valid_acc: 0.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3853             valid_loss: 1.3893, valid_acc: 0.2861\n",
      "epoch: 10, train_loss: 1.1967             valid_loss: 1.3389, valid_acc: 0.3728\n",
      "epoch: 20, train_loss: 1.0951             valid_loss: 1.3419, valid_acc: 0.4249\n",
      "epoch: 30, train_loss: 1.0314             valid_loss: 1.4035, valid_acc: 0.4104\n",
      "epoch: 40, train_loss: 0.9933             valid_loss: 1.4386, valid_acc: 0.4306\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.3853             valid_loss: 1.3893, valid_acc: 0.2861\n",
      "epoch: 10, train_loss: 1.1967             valid_loss: 1.3389, valid_acc: 0.3728\n",
      "epoch: 20, train_loss: 1.0951             valid_loss: 1.3419, valid_acc: 0.4249\n",
      "epoch: 30, train_loss: 1.0314             valid_loss: 1.4035, valid_acc: 0.4104\n",
      "epoch: 40, train_loss: 0.9933             valid_loss: 1.4386, valid_acc: 0.4306\n",
      "epoch: 50, train_loss: 0.9522             valid_loss: 1.4800, valid_acc: 0.3960\n",
      "epoch: 60, train_loss: 0.9052             valid_loss: 1.5276, valid_acc: 0.3931\n",
      "epoch: 70, train_loss: 0.8754             valid_loss: 1.5593, valid_acc: 0.4046\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3853             valid_loss: 1.3893, valid_acc: 0.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_loss: 1.1967             valid_loss: 1.3389, valid_acc: 0.3728\n",
      "epoch: 20, train_loss: 1.0951             valid_loss: 1.3419, valid_acc: 0.4249\n",
      "epoch: 30, train_loss: 1.0314             valid_loss: 1.4035, valid_acc: 0.4104\n",
      "epoch: 40, train_loss: 0.9933             valid_loss: 1.4386, valid_acc: 0.4306\n",
      "epoch: 50, train_loss: 0.9522             valid_loss: 1.4800, valid_acc: 0.3960\n",
      "epoch: 60, train_loss: 0.9052             valid_loss: 1.5276, valid_acc: 0.3931\n",
      "epoch: 70, train_loss: 0.8754             valid_loss: 1.5593, valid_acc: 0.4046\n",
      "epoch: 80, train_loss: 0.8499             valid_loss: 1.6084, valid_acc: 0.4277\n",
      "epoch: 90, train_loss: 0.8541             valid_loss: 1.6682, valid_acc: 0.4220\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.3853             valid_loss: 1.3893, valid_acc: 0.2861\n",
      "epoch: 10, train_loss: 1.1967             valid_loss: 1.3389, valid_acc: 0.3728\n",
      "epoch: 20, train_loss: 1.0951             valid_loss: 1.3419, valid_acc: 0.4249\n",
      "epoch: 30, train_loss: 1.0314             valid_loss: 1.4035, valid_acc: 0.4104\n",
      "epoch: 40, train_loss: 0.9933             valid_loss: 1.4386, valid_acc: 0.4306\n",
      "epoch: 50, train_loss: 0.9522             valid_loss: 1.4800, valid_acc: 0.3960\n",
      "epoch: 60, train_loss: 0.9052             valid_loss: 1.5276, valid_acc: 0.3931\n",
      "epoch: 70, train_loss: 0.8754             valid_loss: 1.5593, valid_acc: 0.4046\n",
      "epoch: 80, train_loss: 0.8499             valid_loss: 1.6084, valid_acc: 0.4277\n",
      "epoch: 90, train_loss: 0.8541             valid_loss: 1.6682, valid_acc: 0.4220\n",
      "epoch: 100, train_loss: 0.8091             valid_loss: 1.7286, valid_acc: 0.4249\n",
      "epoch: 110, train_loss: 0.7948             valid_loss: 1.8083, valid_acc: 0.3815\n",
      "epoch: 120, train_loss: 0.7701             valid_loss: 1.9076, valid_acc: 0.3873\n",
      "epoch: 130, train_loss: 0.7638             valid_loss: 1.9108, valid_acc: 0.4104\n",
      "epoch: 140, train_loss: 0.7590             valid_loss: 1.9559, valid_acc: 0.4191\n",
      "epoch: 150, train_loss: 0.7529             valid_loss: 2.0215, valid_acc: 0.4133\n",
      "epoch: 160, train_loss: 0.7378             valid_loss: 2.0734, valid_acc: 0.4162\n",
      "epoch: 170, train_loss: 0.7342             valid_loss: 2.1216, valid_acc: 0.4104\n",
      "epoch: 180, train_loss: 0.7151             valid_loss: 2.1929, valid_acc: 0.4133\n",
      "epoch: 190, train_loss: 0.7045             valid_loss: 2.2164, valid_acc: 0.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3852             valid_loss: 1.3661, valid_acc: 0.3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3852             valid_loss: 1.3661, valid_acc: 0.3035\n",
      "epoch: 10, train_loss: 1.1224             valid_loss: 1.3350, valid_acc: 0.3902\n",
      "epoch: 20, train_loss: 0.9840             valid_loss: 1.3899, valid_acc: 0.3931\n",
      "epoch: 30, train_loss: 0.8789             valid_loss: 1.4364, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7891             valid_loss: 1.5433, valid_acc: 0.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3852             valid_loss: 1.3661, valid_acc: 0.3035\n",
      "epoch: 10, train_loss: 1.1224             valid_loss: 1.3350, valid_acc: 0.3902\n",
      "epoch: 20, train_loss: 0.9840             valid_loss: 1.3899, valid_acc: 0.3931\n",
      "epoch: 30, train_loss: 0.8789             valid_loss: 1.4364, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7891             valid_loss: 1.5433, valid_acc: 0.4104\n",
      "epoch: 50, train_loss: 0.7152             valid_loss: 1.6288, valid_acc: 0.4046\n",
      "epoch: 60, train_loss: 0.6444             valid_loss: 1.7546, valid_acc: 0.4075\n",
      "epoch: 70, train_loss: 0.6088             valid_loss: 1.7979, valid_acc: 0.4364\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.3852             valid_loss: 1.3661, valid_acc: 0.3035\n",
      "epoch: 10, train_loss: 1.1224             valid_loss: 1.3350, valid_acc: 0.3902\n",
      "epoch: 20, train_loss: 0.9840             valid_loss: 1.3899, valid_acc: 0.3931\n",
      "epoch: 30, train_loss: 0.8789             valid_loss: 1.4364, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7891             valid_loss: 1.5433, valid_acc: 0.4104\n",
      "epoch: 50, train_loss: 0.7152             valid_loss: 1.6288, valid_acc: 0.4046\n",
      "epoch: 60, train_loss: 0.6444             valid_loss: 1.7546, valid_acc: 0.4075\n",
      "epoch: 70, train_loss: 0.6088             valid_loss: 1.7979, valid_acc: 0.4364\n",
      "epoch: 80, train_loss: 0.5274             valid_loss: 1.9383, valid_acc: 0.4220\n",
      "epoch: 90, train_loss: 0.4940             valid_loss: 2.1502, valid_acc: 0.4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3852             valid_loss: 1.3661, valid_acc: 0.3035\n",
      "epoch: 10, train_loss: 1.1224             valid_loss: 1.3350, valid_acc: 0.3902\n",
      "epoch: 20, train_loss: 0.9840             valid_loss: 1.3899, valid_acc: 0.3931\n",
      "epoch: 30, train_loss: 0.8789             valid_loss: 1.4364, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7891             valid_loss: 1.5433, valid_acc: 0.4104\n",
      "epoch: 50, train_loss: 0.7152             valid_loss: 1.6288, valid_acc: 0.4046\n",
      "epoch: 60, train_loss: 0.6444             valid_loss: 1.7546, valid_acc: 0.4075\n",
      "epoch: 70, train_loss: 0.6088             valid_loss: 1.7979, valid_acc: 0.4364\n",
      "epoch: 80, train_loss: 0.5274             valid_loss: 1.9383, valid_acc: 0.4220\n",
      "epoch: 90, train_loss: 0.4940             valid_loss: 2.1502, valid_acc: 0.4335\n",
      "epoch: 100, train_loss: 0.4381             valid_loss: 2.1216, valid_acc: 0.4249\n",
      "epoch: 110, train_loss: 0.4498             valid_loss: 2.2405, valid_acc: 0.4306\n",
      "epoch: 120, train_loss: 0.3701             valid_loss: 2.3704, valid_acc: 0.4364\n",
      "epoch: 130, train_loss: 0.4148             valid_loss: 2.4778, valid_acc: 0.4277\n",
      "epoch: 140, train_loss: 0.3431             valid_loss: 2.5759, valid_acc: 0.4075\n",
      "epoch: 150, train_loss: 0.3050             valid_loss: 2.6303, valid_acc: 0.4104\n",
      "epoch: 160, train_loss: 0.3412             valid_loss: 2.7287, valid_acc: 0.4191\n",
      "epoch: 170, train_loss: 0.2717             valid_loss: 2.8462, valid_acc: 0.4306\n",
      "epoch: 180, train_loss: 0.2428             valid_loss: 2.9424, valid_acc: 0.4191\n",
      "epoch: 190, train_loss: 0.2422             valid_loss: 3.0432, valid_acc: 0.4133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n",
      "epoch: 10, train_loss: 1.1177             valid_loss: 1.3440, valid_acc: 0.4075\n",
      "epoch: 20, train_loss: 0.9730             valid_loss: 1.4157, valid_acc: 0.3786\n",
      "epoch: 30, train_loss: 0.8580             valid_loss: 1.4899, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7546             valid_loss: 1.5930, valid_acc: 0.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n",
      "epoch: 10, train_loss: 1.1177             valid_loss: 1.3440, valid_acc: 0.4075\n",
      "epoch: 20, train_loss: 0.9730             valid_loss: 1.4157, valid_acc: 0.3786\n",
      "epoch: 30, train_loss: 0.8580             valid_loss: 1.4899, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7546             valid_loss: 1.5930, valid_acc: 0.3960\n",
      "epoch: 50, train_loss: 0.6793             valid_loss: 1.7262, valid_acc: 0.4335\n",
      "epoch: 60, train_loss: 0.6054             valid_loss: 1.8375, valid_acc: 0.4191\n",
      "epoch: 70, train_loss: 0.5294             valid_loss: 1.9429, valid_acc: 0.4046\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n",
      "epoch: 10, train_loss: 1.1177             valid_loss: 1.3440, valid_acc: 0.4075\n",
      "epoch: 20, train_loss: 0.9730             valid_loss: 1.4157, valid_acc: 0.3786\n",
      "epoch: 30, train_loss: 0.8580             valid_loss: 1.4899, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7546             valid_loss: 1.5930, valid_acc: 0.3960\n",
      "epoch: 50, train_loss: 0.6793             valid_loss: 1.7262, valid_acc: 0.4335\n",
      "epoch: 60, train_loss: 0.6054             valid_loss: 1.8375, valid_acc: 0.4191\n",
      "epoch: 70, train_loss: 0.5294             valid_loss: 1.9429, valid_acc: 0.4046\n",
      "epoch: 80, train_loss: 0.4783             valid_loss: 2.0621, valid_acc: 0.4364\n",
      "epoch: 90, train_loss: 0.4335             valid_loss: 2.1641, valid_acc: 0.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n",
      "epoch: 10, train_loss: 1.1177             valid_loss: 1.3440, valid_acc: 0.4075\n",
      "epoch: 20, train_loss: 0.9730             valid_loss: 1.4157, valid_acc: 0.3786\n",
      "epoch: 30, train_loss: 0.8580             valid_loss: 1.4899, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7546             valid_loss: 1.5930, valid_acc: 0.3960\n",
      "epoch: 50, train_loss: 0.6793             valid_loss: 1.7262, valid_acc: 0.4335\n",
      "epoch: 60, train_loss: 0.6054             valid_loss: 1.8375, valid_acc: 0.4191\n",
      "epoch: 70, train_loss: 0.5294             valid_loss: 1.9429, valid_acc: 0.4046\n",
      "epoch: 80, train_loss: 0.4783             valid_loss: 2.0621, valid_acc: 0.4364\n",
      "epoch: 90, train_loss: 0.4335             valid_loss: 2.1641, valid_acc: 0.4220\n",
      "epoch: 100, train_loss: 0.4018             valid_loss: 2.2890, valid_acc: 0.4364\n",
      "epoch: 110, train_loss: 0.3779             valid_loss: 2.4173, valid_acc: 0.4364\n",
      "epoch: 120, train_loss: 0.3269             valid_loss: 2.4823, valid_acc: 0.4422\n",
      "epoch: 130, train_loss: 0.3039             valid_loss: 2.6295, valid_acc: 0.4133\n",
      "epoch: 140, train_loss: 0.4176             valid_loss: 2.6562, valid_acc: 0.4451\n",
      "epoch: 150, train_loss: 0.2558             valid_loss: 2.7345, valid_acc: 0.4249\n",
      "epoch: 160, train_loss: 0.2334             valid_loss: 2.8678, valid_acc: 0.4364\n",
      "epoch: 170, train_loss: 0.2152             valid_loss: 2.9747, valid_acc: 0.4277\n",
      "epoch: 180, train_loss: 0.2068             valid_loss: 3.0558, valid_acc: 0.4249\n",
      "epoch: 190, train_loss: 0.1873             valid_loss: 3.1817, valid_acc: 0.4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3971             valid_loss: 1.4037, valid_acc: 0.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3971             valid_loss: 1.4037, valid_acc: 0.2601\n",
      "epoch: 10, train_loss: 1.3602             valid_loss: 1.3868, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3354             valid_loss: 1.3783, valid_acc: 0.2890\n",
      "epoch: 30, train_loss: 1.3138             valid_loss: 1.3723, valid_acc: 0.2919\n",
      "epoch: 40, train_loss: 1.2924             valid_loss: 1.3663, valid_acc: 0.3121\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3971             valid_loss: 1.4037, valid_acc: 0.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_loss: 1.3602             valid_loss: 1.3868, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3354             valid_loss: 1.3783, valid_acc: 0.2890\n",
      "epoch: 30, train_loss: 1.3138             valid_loss: 1.3723, valid_acc: 0.2919\n",
      "epoch: 40, train_loss: 1.2924             valid_loss: 1.3663, valid_acc: 0.3121\n",
      "epoch: 50, train_loss: 1.2716             valid_loss: 1.3600, valid_acc: 0.3295\n",
      "epoch: 60, train_loss: 1.2515             valid_loss: 1.3554, valid_acc: 0.3382\n",
      "epoch: 70, train_loss: 1.2327             valid_loss: 1.3496, valid_acc: 0.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3971             valid_loss: 1.4037, valid_acc: 0.2601\n",
      "epoch: 10, train_loss: 1.3602             valid_loss: 1.3868, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3354             valid_loss: 1.3783, valid_acc: 0.2890\n",
      "epoch: 30, train_loss: 1.3138             valid_loss: 1.3723, valid_acc: 0.2919\n",
      "epoch: 40, train_loss: 1.2924             valid_loss: 1.3663, valid_acc: 0.3121\n",
      "epoch: 50, train_loss: 1.2716             valid_loss: 1.3600, valid_acc: 0.3295\n",
      "epoch: 60, train_loss: 1.2515             valid_loss: 1.3554, valid_acc: 0.3382\n",
      "epoch: 70, train_loss: 1.2327             valid_loss: 1.3496, valid_acc: 0.3382\n",
      "epoch: 80, train_loss: 1.2157             valid_loss: 1.3444, valid_acc: 0.3497\n",
      "epoch: 90, train_loss: 1.2004             valid_loss: 1.3407, valid_acc: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.3971             valid_loss: 1.4037, valid_acc: 0.2601\n",
      "epoch: 10, train_loss: 1.3602             valid_loss: 1.3868, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3354             valid_loss: 1.3783, valid_acc: 0.2890\n",
      "epoch: 30, train_loss: 1.3138             valid_loss: 1.3723, valid_acc: 0.2919\n",
      "epoch: 40, train_loss: 1.2924             valid_loss: 1.3663, valid_acc: 0.3121\n",
      "epoch: 50, train_loss: 1.2716             valid_loss: 1.3600, valid_acc: 0.3295\n",
      "epoch: 60, train_loss: 1.2515             valid_loss: 1.3554, valid_acc: 0.3382\n",
      "epoch: 70, train_loss: 1.2327             valid_loss: 1.3496, valid_acc: 0.3382\n",
      "epoch: 80, train_loss: 1.2157             valid_loss: 1.3444, valid_acc: 0.3497\n",
      "epoch: 90, train_loss: 1.2004             valid_loss: 1.3407, valid_acc: 0.3642\n",
      "epoch: 100, train_loss: 1.1852             valid_loss: 1.3370, valid_acc: 0.3613\n",
      "epoch: 110, train_loss: 1.1708             valid_loss: 1.3354, valid_acc: 0.3671\n",
      "epoch: 120, train_loss: 1.1570             valid_loss: 1.3339, valid_acc: 0.3728\n",
      "epoch: 130, train_loss: 1.1447             valid_loss: 1.3319, valid_acc: 0.3642\n",
      "epoch: 140, train_loss: 1.1333             valid_loss: 1.3313, valid_acc: 0.3815\n",
      "epoch: 150, train_loss: 1.1229             valid_loss: 1.3315, valid_acc: 0.3844\n",
      "epoch: 160, train_loss: 1.1130             valid_loss: 1.3314, valid_acc: 0.3931\n",
      "epoch: 170, train_loss: 1.1026             valid_loss: 1.3326, valid_acc: 0.4017\n",
      "epoch: 180, train_loss: 1.0930             valid_loss: 1.3357, valid_acc: 0.4075\n",
      "epoch: 190, train_loss: 1.0841             valid_loss: 1.3399, valid_acc: 0.4075\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.4101             valid_loss: 1.3938, valid_acc: 0.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4101             valid_loss: 1.3938, valid_acc: 0.3295\n",
      "epoch: 10, train_loss: 1.3406             valid_loss: 1.3694, valid_acc: 0.3237\n",
      "epoch: 20, train_loss: 1.3072             valid_loss: 1.3627, valid_acc: 0.3237\n",
      "epoch: 30, train_loss: 1.2783             valid_loss: 1.3548, valid_acc: 0.3353\n",
      "epoch: 40, train_loss: 1.2497             valid_loss: 1.3485, valid_acc: 0.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4101             valid_loss: 1.3938, valid_acc: 0.3295\n",
      "epoch: 10, train_loss: 1.3406             valid_loss: 1.3694, valid_acc: 0.3237\n",
      "epoch: 20, train_loss: 1.3072             valid_loss: 1.3627, valid_acc: 0.3237\n",
      "epoch: 30, train_loss: 1.2783             valid_loss: 1.3548, valid_acc: 0.3353\n",
      "epoch: 40, train_loss: 1.2497             valid_loss: 1.3485, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2217             valid_loss: 1.3442, valid_acc: 0.3382\n",
      "epoch: 60, train_loss: 1.1952             valid_loss: 1.3392, valid_acc: 0.3439\n",
      "epoch: 70, train_loss: 1.1701             valid_loss: 1.3364, valid_acc: 0.3526\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.4101             valid_loss: 1.3938, valid_acc: 0.3295\n",
      "epoch: 10, train_loss: 1.3406             valid_loss: 1.3694, valid_acc: 0.3237\n",
      "epoch: 20, train_loss: 1.3072             valid_loss: 1.3627, valid_acc: 0.3237\n",
      "epoch: 30, train_loss: 1.2783             valid_loss: 1.3548, valid_acc: 0.3353\n",
      "epoch: 40, train_loss: 1.2497             valid_loss: 1.3485, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2217             valid_loss: 1.3442, valid_acc: 0.3382\n",
      "epoch: 60, train_loss: 1.1952             valid_loss: 1.3392, valid_acc: 0.3439\n",
      "epoch: 70, train_loss: 1.1701             valid_loss: 1.3364, valid_acc: 0.3526\n",
      "epoch: 80, train_loss: 1.1465             valid_loss: 1.3360, valid_acc: 0.3671\n",
      "epoch: 90, train_loss: 1.1247             valid_loss: 1.3348, valid_acc: 0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4101             valid_loss: 1.3938, valid_acc: 0.3295\n",
      "epoch: 10, train_loss: 1.3406             valid_loss: 1.3694, valid_acc: 0.3237\n",
      "epoch: 20, train_loss: 1.3072             valid_loss: 1.3627, valid_acc: 0.3237\n",
      "epoch: 30, train_loss: 1.2783             valid_loss: 1.3548, valid_acc: 0.3353\n",
      "epoch: 40, train_loss: 1.2497             valid_loss: 1.3485, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2217             valid_loss: 1.3442, valid_acc: 0.3382\n",
      "epoch: 60, train_loss: 1.1952             valid_loss: 1.3392, valid_acc: 0.3439\n",
      "epoch: 70, train_loss: 1.1701             valid_loss: 1.3364, valid_acc: 0.3526\n",
      "epoch: 80, train_loss: 1.1465             valid_loss: 1.3360, valid_acc: 0.3671\n",
      "epoch: 90, train_loss: 1.1247             valid_loss: 1.3348, valid_acc: 0.3815\n",
      "epoch: 100, train_loss: 1.1044             valid_loss: 1.3353, valid_acc: 0.3873\n",
      "epoch: 110, train_loss: 1.0851             valid_loss: 1.3360, valid_acc: 0.3960\n",
      "epoch: 120, train_loss: 1.0673             valid_loss: 1.3401, valid_acc: 0.3960\n",
      "epoch: 130, train_loss: 1.0508             valid_loss: 1.3444, valid_acc: 0.3960\n",
      "epoch: 140, train_loss: 1.0348             valid_loss: 1.3491, valid_acc: 0.3988\n",
      "epoch: 150, train_loss: 1.0189             valid_loss: 1.3542, valid_acc: 0.4046\n",
      "epoch: 160, train_loss: 1.0044             valid_loss: 1.3597, valid_acc: 0.3988\n",
      "epoch: 170, train_loss: 0.9904             valid_loss: 1.3637, valid_acc: 0.4046\n",
      "epoch: 180, train_loss: 0.9766             valid_loss: 1.3679, valid_acc: 0.3988\n",
      "epoch: 190, train_loss: 0.9633             valid_loss: 1.3738, valid_acc: 0.4017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4396             valid_loss: 1.4219, valid_acc: 0.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4396             valid_loss: 1.4219, valid_acc: 0.2514\n",
      "epoch: 10, train_loss: 1.3458             valid_loss: 1.3773, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3037             valid_loss: 1.3639, valid_acc: 0.3121\n",
      "epoch: 30, train_loss: 1.2698             valid_loss: 1.3551, valid_acc: 0.3237\n",
      "epoch: 40, train_loss: 1.2387             valid_loss: 1.3486, valid_acc: 0.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4396             valid_loss: 1.4219, valid_acc: 0.2514\n",
      "epoch: 10, train_loss: 1.3458             valid_loss: 1.3773, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3037             valid_loss: 1.3639, valid_acc: 0.3121\n",
      "epoch: 30, train_loss: 1.2698             valid_loss: 1.3551, valid_acc: 0.3237\n",
      "epoch: 40, train_loss: 1.2387             valid_loss: 1.3486, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2112             valid_loss: 1.3420, valid_acc: 0.3497\n",
      "epoch: 60, train_loss: 1.1857             valid_loss: 1.3385, valid_acc: 0.3555\n",
      "epoch: 70, train_loss: 1.1623             valid_loss: 1.3381, valid_acc: 0.3728\n",
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 1.4396             valid_loss: 1.4219, valid_acc: 0.2514\n",
      "epoch: 10, train_loss: 1.3458             valid_loss: 1.3773, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3037             valid_loss: 1.3639, valid_acc: 0.3121\n",
      "epoch: 30, train_loss: 1.2698             valid_loss: 1.3551, valid_acc: 0.3237\n",
      "epoch: 40, train_loss: 1.2387             valid_loss: 1.3486, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2112             valid_loss: 1.3420, valid_acc: 0.3497\n",
      "epoch: 60, train_loss: 1.1857             valid_loss: 1.3385, valid_acc: 0.3555\n",
      "epoch: 70, train_loss: 1.1623             valid_loss: 1.3381, valid_acc: 0.3728\n",
      "epoch: 80, train_loss: 1.1410             valid_loss: 1.3363, valid_acc: 0.3844\n",
      "epoch: 90, train_loss: 1.1204             valid_loss: 1.3382, valid_acc: 0.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4396             valid_loss: 1.4219, valid_acc: 0.2514\n",
      "epoch: 10, train_loss: 1.3458             valid_loss: 1.3773, valid_acc: 0.2746\n",
      "epoch: 20, train_loss: 1.3037             valid_loss: 1.3639, valid_acc: 0.3121\n",
      "epoch: 30, train_loss: 1.2698             valid_loss: 1.3551, valid_acc: 0.3237\n",
      "epoch: 40, train_loss: 1.2387             valid_loss: 1.3486, valid_acc: 0.3382\n",
      "epoch: 50, train_loss: 1.2112             valid_loss: 1.3420, valid_acc: 0.3497\n",
      "epoch: 60, train_loss: 1.1857             valid_loss: 1.3385, valid_acc: 0.3555\n",
      "epoch: 70, train_loss: 1.1623             valid_loss: 1.3381, valid_acc: 0.3728\n",
      "epoch: 80, train_loss: 1.1410             valid_loss: 1.3363, valid_acc: 0.3844\n",
      "epoch: 90, train_loss: 1.1204             valid_loss: 1.3382, valid_acc: 0.3960\n",
      "epoch: 100, train_loss: 1.1014             valid_loss: 1.3399, valid_acc: 0.4017\n",
      "epoch: 110, train_loss: 1.0832             valid_loss: 1.3459, valid_acc: 0.4133\n",
      "epoch: 120, train_loss: 1.0655             valid_loss: 1.3467, valid_acc: 0.3902\n",
      "epoch: 130, train_loss: 1.0483             valid_loss: 1.3515, valid_acc: 0.4104\n",
      "epoch: 140, train_loss: 1.0319             valid_loss: 1.3568, valid_acc: 0.3988\n",
      "epoch: 150, train_loss: 1.0157             valid_loss: 1.3637, valid_acc: 0.4075\n",
      "epoch: 160, train_loss: 1.0000             valid_loss: 1.3696, valid_acc: 0.4133\n",
      "epoch: 170, train_loss: 0.9851             valid_loss: 1.3768, valid_acc: 0.4104\n",
      "epoch: 180, train_loss: 0.9705             valid_loss: 1.3884, valid_acc: 0.4133\n",
      "epoch: 190, train_loss: 0.9556             valid_loss: 1.3937, valid_acc: 0.4133\n",
      "CPU times: user 3min 22s, sys: 1min 3s, total: 4min 25s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_names = list(params_.keys())\n",
    "# zip with parameter names in order to get original property\n",
    "param_values = (zip(param_names, x) for x in product(*params_.values()))\n",
    "\n",
    "result_val_acc = list()\n",
    "output = pd.DataFrame()\n",
    "for paramset in param_values:\n",
    "    # use the dict from iterator of tuples constructor\n",
    "    dict_temp = dict(paramset)\n",
    "    output = output.append(dict_temp, ignore_index=True)\n",
    "    # operando la grilla para tener el accuracy y guardar en lista\n",
    "\n",
    "\n",
    "    result_val_acc.append(grid_excercise(X=X,\n",
    "                y=y,\n",
    "                RANDOM_SEED=123,\n",
    "                BATCH_SIZE=50,\n",
    "                NUM_EPOCHS=dict_temp['epochs'],\n",
    "                lr=dict_temp['learning_rate'],\n",
    "                NUM_HIDDEN = dict_temp['NUM_HIDDEN'],\n",
    "                DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'), #carga de la red neuronal en la CPU o en la GPU\n",
    "                get_results= False\n",
    "                    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEJOR COMBINACIÓN DE Parametros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>NUM_HIDDEN</th>\n",
       "      <th>epochs</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.439306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  learning_rate  NUM_HIDDEN  epochs   acc_val\n",
       "0     13            0.1       100.0   100.0  0.439306"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.assign(acc_val = result_val_acc)\n",
    "print('MEJOR COMBINACIÓN DE Parametros')\n",
    "best_params = output.loc[output.acc_val == output.acc_val.max()].reset_index()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR= best_params.learning_rate[0]\n",
    "NUM_EPOCHS = int(best_params.epochs[0])\n",
    "NUM_HIDDEN = int(best_params.NUM_HIDDEN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam muestra de entrenamiento\n",
      "torch.Size([807, 50])\n",
      "torch.Size([807])\n",
      "epoch: 0, train_loss: 1.4035             valid_loss: 1.3774, valid_acc: 0.2803\n",
      "epoch: 10, train_loss: 1.1177             valid_loss: 1.3440, valid_acc: 0.4075\n",
      "epoch: 20, train_loss: 0.9730             valid_loss: 1.4157, valid_acc: 0.3786\n",
      "epoch: 30, train_loss: 0.8580             valid_loss: 1.4899, valid_acc: 0.4220\n",
      "epoch: 40, train_loss: 0.7546             valid_loss: 1.5930, valid_acc: 0.3960\n",
      "epoch: 50, train_loss: 0.6793             valid_loss: 1.7262, valid_acc: 0.4335\n",
      "epoch: 60, train_loss: 0.6054             valid_loss: 1.8375, valid_acc: 0.4191\n",
      "epoch: 70, train_loss: 0.5294             valid_loss: 1.9429, valid_acc: 0.4046\n",
      "epoch: 80, train_loss: 0.4783             valid_loss: 2.0621, valid_acc: 0.4364\n",
      "epoch: 90, train_loss: 0.4335             valid_loss: 2.1641, valid_acc: 0.4220\n"
     ]
    }
   ],
   "source": [
    "train_losses,train_accs,valid_losses,valid_accs = grid_excercise(X=X,\n",
    "                                                                 y=y,\n",
    "                                                                 RANDOM_SEED=123,\n",
    "                                                                 BATCH_SIZE=50,\n",
    "                                                                 NUM_EPOCHS=NUM_EPOCHS,\n",
    "                                                                 lr=LR,\n",
    "                                                                 NUM_HIDDEN = NUM_HIDDEN,\n",
    "                                                                 DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'), #carga de la red neuronal en la CPU o en la GPU\n",
    "                                                                 get_results= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(NUM_EPOCHS), train_losses, 'r', label='train')\n",
    "plt.plot(range(NUM_EPOCHS), valid_losses, 'b', label = 'valid')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(NUM_EPOCHS), valid_accs, 'y', label = 'test')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "Este ejercicio, es más bien un tutorial de como realizar un clasificador de ventanas de palabras, acercandónos a un problema de NLP conocido como \"Name Entity Recognition\" (NER), el cual busca clasificar cada palabra en por ejemplo si es un nombre, pronombre, verbo, lugar, etc. Esto es muy importante, porque introduce varias cuestiones claves que se usan en el NLP con deep learning. Al final, el ejercicio será (1) entender cada parte y (2) realizar el mismo procedimiento pero clasificando entre varios tipos de palabras (no sólo una). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Clasificación de ventanas de palabras (Word Window Classification) paso a paso\n",
    "\n",
    "En esta tarea de NLP aprenderemos:\n",
    "\n",
    "1. Datos: creación de un conjunto de datos de tensores por batches\n",
    "2. Modelado\n",
    "3. Entrenamiento\n",
    "4. Predicción\n",
    "\n",
    "En esta sección, nuestro objetivo será entrenar un modelo que encuentre las palabras en una oración correspondiente a una 'UBICACIÓN', que siempre tendrá un intervalo de '1' (lo que significa que 'San Francisco' no se reconocerá como un `UBICACIÓN`). Nuestra tarea se llama `Clasificación de ventana de palabras` por una razón. En lugar de permitir que nuestro modelo solo eche un vistazo a una palabra en cada paso hacia adelante, nos gustaría que pudiera considerar el contexto de la palabra en cuestión. Es decir, para cada palabra, queremos que nuestro modelo sea consciente de las palabras que lo rodean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:01:54.597689Z",
     "start_time": "2022-02-28T12:01:54.594870Z"
    },
    "lang": "es"
   },
   "outputs": [],
   "source": [
    "# Nuestros datos sin procesar, que consisten en oraciones\n",
    "corpus = [\n",
    "          \"Nosotros siempre venimos a París\",\n",
    "          \"El profesor es de Australia\",\n",
    "          \"Yo vivo en Bogotá\",\n",
    "          \"Él viene de Taiwán\",\n",
    "          \"La capital de Turquía es Ankara\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### Preprocesamiento\n",
    "\n",
    "Para facilitar el aprendizaje de nuestros modelos, generalmente aplicamos algunos pasos de preprocesamiento a nuestros datos. Esto es especialmente importante cuando se trata de datos de texto. Estos son algunos ejemplos de preprocesamiento de texto:\n",
    "* **Tokenización**: Tokenización de oraciones en palabras.\n",
    "* **Lowercasing**: Cambiar todas las letras a minúsculas.\n",
    "* **Eliminación de ruido**: Eliminación de caracteres especiales (como signos de puntuación o quitar tíldes).\n",
    "* **Eliminación de palabras vacías**: eliminación de palabras de uso común.\n",
    "\n",
    "Los pasos de preprocesamiento necesarios están determinados por la tarea en cuestión. Por ejemplo, aunque es útil eliminar caracteres especiales en algunas tareas, para otras pueden ser importantes (por ejemplo, si estamos hablando de varios idiomas). Para nuestra tarea, escribiremos en minúsculas nuestras palabras y tokenizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:29:42.298122Z",
     "start_time": "2022-02-28T17:29:42.294408Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "def quitartildes(s):\n",
    "    # -> NFD y eliminar diacríticos\n",
    "    s = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", s), 0, re.I\n",
    "        )\n",
    "\n",
    "    # -> NFCNosotros\n",
    "    return normalize( 'NFC', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:02:33.349815Z",
     "start_time": "2022-02-28T12:02:33.338195Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTGn8ANTzZXT",
    "lang": "en",
    "outputId": "0ed249ae-7272-4400-9319-d7cc9dca02d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nosotros', 'siempre', 'venimos', 'a', 'paris'],\n",
       " ['el', 'profesor', 'es', 'de', 'australia'],\n",
       " ['yo', 'vivo', 'en', 'bogota'],\n",
       " ['el', 'viene', 'de', 'taiwan'],\n",
       " ['la', 'capital', 'de', 'turquia', 'es', 'ankara']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La función de preprocesamiento que usaremos para generar nuestros ejemplos de entrenamiento\n",
    "# Nuestra función es simple, ponemos las letras en minúsculas, quitamos tildes\n",
    "# y luego tokenizamos las palabras.\n",
    "def preprocess_sentence(sentence):\n",
    "  return quitartildes(sentence).lower().split()\n",
    "\n",
    "# Crea nuestro conjunto de entrenamiento\n",
    "train_sentences = [preprocess_sentence(sent) for sent in corpus]\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Para cada ejemplo de entrenamiento que tengamos, también deberíamos tener una etiqueta correspondiente. Recuerde que el objetivo de nuestro modelo era determinar qué palabras corresponden a una `UBICACIÓN`. Es decir, queremos que nuestro modelo genere `0` para todas las palabras que no sean `UBICACION` y `1` para las que sean `UBICACION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:04:05.416956Z",
     "start_time": "2022-02-28T12:04:05.411731Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wo1kcMAHFw7",
    "outputId": "f064cb0b-7176-4825-bab9-f7c00accff3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set de ubicaciones que aparecen en el corpus\n",
    "locations = set([\"australia\", \"ankara\", \"paris\", \"bogota\", \"taiwan\", \"turquia\"])\n",
    "\n",
    "# Nuestras etiquetas de entrenamiento\n",
    "train_labels = [[1 if word in locations else 0 for word in sent] for sent in train_sentences]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### Convertir palabras a Embeddings\n",
    "\n",
    "Veamos nuestros datos de entrenamiento un poco más de cerca. Cada punto de datos que tenemos es una secuencia de palabras. Por otro lado, sabemos que los modelos de aprendizaje automático funcionan con números en vectores. ¿Cómo vamos a convertir las palabras en números? ¡A través de los embeddings!\n",
    "\n",
    "Imagine que tenemos una tabla de búsqueda de embeddings `E`, donde cada fila corresponde a un embedding. Es decir, cada palabra de nuestro vocabulario tendría una fila de embedding `i` correspondiente en esta tabla. Siempre que queramos encontrar una embedding para una palabra, seguiremos estos pasos:\n",
    "1. Buscar el índice correspondiente `i` de la palabra en la tabla de embedding: `palabra->índice`.\n",
    "2. Indexar en la tabla de embedding y obtener el embedding: `índice->embedding`.\n",
    "\n",
    "Veamos el primer paso. Deberíamos asignar todas las palabras de nuestro vocabulario a un índice correspondiente. Podemos hacerlo de la siguiente manera:\n",
    "1. Encontrando todas las palabras únicas en nuestro corpus.\n",
    "2. Asignando un índice a cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:19:17.566727Z",
     "start_time": "2022-02-28T12:19:17.562687Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjTDlfPyVp5z",
    "lang": "en",
    "outputId": "bce95386-3b75-470b-8c9b-9c2255203c4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ankara',\n",
       " 'australia',\n",
       " 'bogota',\n",
       " 'capital',\n",
       " 'de',\n",
       " 'el',\n",
       " 'en',\n",
       " 'es',\n",
       " 'la',\n",
       " 'nosotros',\n",
       " 'paris',\n",
       " 'profesor',\n",
       " 'siempre',\n",
       " 'taiwan',\n",
       " 'turquia',\n",
       " 'venimos',\n",
       " 'viene',\n",
       " 'vivo',\n",
       " 'yo'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encuentra todas las palabras únicas en nuestro corpus\n",
    "vocabulary = set(w for s in train_sentences for w in s)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "`vocabulary` ahora contiene todas las palabras en nuestro corpus. Por otro lado, durante la (evaluación con el conjunto de) prueba, podemos ver palabras que no están contenidas en nuestro vocabulario. Si podemos encontrar una forma de representar las palabras desconocidas, nuestro modelo aún podría razonar sobre si son una 'UBICACIÓN' o no, ya que también estamos mirando las palabras vecinas para cada predicción.\n",
    "\n",
    "Introducimos un token especial, `<unk>`, para abordar las palabras que están fuera del vocabulario. Podríamos elegir otra cadena para nuestro token desconocido si quisiéramos. El único requisito aquí es que nuestro token debe ser único: solo debemos usar este token para palabras desconocidas. También agregaremos este token especial a nuestro vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:20:46.951737Z",
     "start_time": "2022-02-28T12:20:46.949319Z"
    },
    "lang": "es"
   },
   "outputs": [],
   "source": [
    "# Agrega el token desconocido a nuestro vocabulario\n",
    "vocabulary.add(\"<unk>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Anteriormente mencionamos que nuestra tarea se llamaba \"Clasificación de ventana de palabras\" porque nuestro modelo está mirando las palabras circundantes además de la palabra central, cuando se necesita hacer una predicción.\n",
    "\n",
    "Por ejemplo, tomemos la oración \"Nosotros siempre venimos a París\". La etiqueta de entrenamiento correspondiente para esta oración es `0, 0, 0, 0, 1` ya que solo París, la última palabra, es una `UBICACIÓN`. En una sola pasada (es decir, una llamada a `forward()`), nuestro modelo intentará generar la etiqueta correcta para una palabra. Digamos que nuestro modelo intenta generar la etiqueta correcta `1` para `París`. Si solo permitimos que nuestro modelo vea `París`, pero nada más, nos perderemos información importante, como por ejemplo, de que la palabra 'a' aparece muchas veces con `UBICACIONES`.\n",
    "\n",
    "Las ventanas de palabras permiten que nuestro modelo considere `+N` o `-N` palabras alrededor de cada palabra al hacer una predicción. En nuestro ejemplo anterior para `París`, si tenemos un tamaño de ventana de 1, eso significa que nuestro modelo mirará las palabras que vienen inmediatamente antes e inmediatamente después de `París`, que son `a` y, *ninguna palabra*. Ahora bien, esto plantea otro problema. `París` está al final de nuestra oración, por lo que no hay otra palabra que la siga. Recuerde que definimos las dimensiones de entrada de nuestros modelos en `PyTorch` cuando los inicializamos. Si establecemos el tamaño de la ventana en `1`, significa que nuestro modelo aceptará `3` palabras en cada paso. No podemos hacer que nuestro modelo espere `2` palabras de vez en cuando.\n",
    "\n",
    "La solución es introducir un token especial, `<pad>`, que se agregará a nuestras oraciones para asegurarnos de que cada palabra tenga una ventana válida alrededor. Similar al token `<unk>`, podríamos elegir otra cadena para nuestro token de relleno si quisiéramos, siempre y cuando nos aseguremos de que se use para un propósito único."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:24:59.410072Z",
     "start_time": "2022-02-28T12:24:59.405189Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVQsjYi6ZegI",
    "lang": "en",
    "outputId": "f0f45f18-0e91-48e5-f5b7-229c2c36a694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<pad>',\n",
       " 'nosotros',\n",
       " 'siempre',\n",
       " 'venimos',\n",
       " 'a',\n",
       " 'paris',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregua el token <pad> a nuestro vocabulario\n",
    "vocabulary.add(\"<pad>\")\n",
    "\n",
    "# Función que rellena la oración dada\n",
    "# Estamos introduciendo esta función aquí como un ejemplo\n",
    "# Lo utilizaremos más adelante en el tutorial.\n",
    "def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "  window = [pad_token] * window_size\n",
    "  return window + sentence + window\n",
    "\n",
    "# Muestra un ejemplo de relleno\n",
    "window_size = 2\n",
    "pad_window(train_sentences[0], window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ahora que nuestro vocabulario está listo, asignemos un índice a cada una de nuestras palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:51:17.026347Z",
     "start_time": "2022-02-28T12:51:17.020997Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNCTQnKDa4oh",
    "lang": "en",
    "outputId": "dedbe39a-40c2-42e8-be56-96b6d961fd99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 'a': 2,\n",
       " 'ankara': 3,\n",
       " 'australia': 4,\n",
       " 'bogota': 5,\n",
       " 'capital': 6,\n",
       " 'de': 7,\n",
       " 'el': 8,\n",
       " 'en': 9,\n",
       " 'es': 10,\n",
       " 'la': 11,\n",
       " 'nosotros': 12,\n",
       " 'paris': 13,\n",
       " 'profesor': 14,\n",
       " 'siempre': 15,\n",
       " 'taiwan': 16,\n",
       " 'turquia': 17,\n",
       " 'venimos': 18,\n",
       " 'viene': 19,\n",
       " 'vivo': 20,\n",
       " 'yo': 21}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo estamos convirtiendo nuestro vocabulario en una lista para poder indexarla\n",
    "# Aunque ordenar no es necesario, ordenamos para mostrar un diccionario word_to_ind ordenado\n",
    "# Dicho esto, veremos que tener el índice para el token de relleno\n",
    "# como 0 es conveniente ya que algunas funciones de PyTorch lo usan como valor predeterminado\n",
    "# como sucede con nn.utils.rnn.pad_sequence, que veremos en un momento\n",
    "ix_to_word = sorted(list(vocabulary))\n",
    "\n",
    "# Creando un diccionario para encontrar el índice de una palabra dada\n",
    "word_to_ix = {word: ind for ind, word in enumerate(ix_to_word)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:51:20.976293Z",
     "start_time": "2022-02-28T12:51:20.972583Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pt-0SK67hMVo",
    "outputId": "a8516317-65c7-4548-c0ac-6f6711a5370c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ahora, estamos listos para convertir nuestras oraciones de entrenamiento en una secuencia de índices correspondientes a cada token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:52:06.907826Z",
     "start_time": "2022-02-28T12:52:06.901238Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNOxip15bMfH",
    "lang": "en",
    "outputId": "74f8344f-bdeb-4a37-9442-b317013cdc10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración original es: ['nosotros', 'siempre', 'venimos', 'a', 'kuwait']\n",
      "Pasar de palabras a índices: [12, 15, 18, 2, 1]\n",
      "Pasando de índices a palabras: ['nosotros', 'siempre', 'venimos', 'a', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "# Dada una sentencia de tokens, devuelve los índices correspondientes\n",
    "def convert_token_to_indices(sentence, word_to_ix):\n",
    "  indices = []\n",
    "  for token in sentence:\n",
    "    # Comprueba si el token está en nuestro vocabulario. Si es así, obtiene su índice.\n",
    "    # Si no, obtiene el índice del token desconocido.\n",
    "    if token in word_to_ix:\n",
    "      index = word_to_ix[token]\n",
    "    else:\n",
    "      index = word_to_ix[\"<unk>\"]\n",
    "    indices.append(index)\n",
    "  return indices\n",
    "\n",
    "# Versión más compacta de la misma función\n",
    "def _convert_token_to_indices(sentence, word_to_ix):\n",
    "  return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "# Muestra un ejemplo\n",
    "example_sentence = [\"nosotros\", \"siempre\", \"venimos\", \"a\", \"kuwait\"]\n",
    "example_indices = convert_token_to_indices(example_sentence, word_to_ix)\n",
    "restored_example = [ix_to_word[ind] for ind in example_indices]\n",
    "\n",
    "print(f\"La oración original es: {example_sentence}\")\n",
    "print(f\"Pasar de palabras a índices: {example_indices}\")\n",
    "print(f\"Pasando de índices a palabras: {restored_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "En el ejemplo anterior, `kuwait` aparece como `<unk>`, porque no está incluido en nuestro vocabulario. Convirtamos nuestras `train_sentences` a `example_padded_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:52:24.599737Z",
     "start_time": "2022-02-28T12:52:24.595267Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRaKQwSJH-1d",
    "outputId": "ac2c370a-4d6e-41a7-afd2-652c76f6c235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 15, 18, 2, 13],\n",
       " [8, 14, 10, 7, 4],\n",
       " [21, 20, 9, 5],\n",
       " [8, 19, 7, 16],\n",
       " [11, 6, 7, 17, 10, 3]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convirtiendo nuestras sentencias a indices\n",
    "example_padded_indices = [convert_token_to_indices(s, word_to_ix) for s in train_sentences]\n",
    "example_padded_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ahora que tenemos un índice para cada palabra en nuestro vocabulario, podemos crear una tabla de embedding con la clase `nn.Embedding` de `PyTorch`. Se llama de la siguiente manera `nn.Embedding(num_words, embedding_dimension)` donde `num_words` es el número de palabras en nuestro vocabulario y `embedding_dimension` es la dimensión de los embeddings que queremos tener. No hay nada sofisticado en `nn.Embedding`: es solo una clase wrapper alrededor de un tensor dimensional entrenable de tamaño `NxE` , donde `N` es el número de palabras en nuestro vocabulario y `E` es el número de dimensiones incrustadas. Esta tabla es inicialmente aleatoria, pero cambiará con el tiempo. A medida que entrenamos nuestra red, los gradientes se propagarán hacia atrás hasta la capa de embedding y, por lo tanto, nuestros embeddings de palabras se actualizarán. Posteriormente, inicializaremos la capa de embedding que usaremos para nuestro modelo dentro de nuestro modelo, pero a continuación mostramos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:54:24.057777Z",
     "start_time": "2022-02-28T12:54:24.052087Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4AgHzv91VXx",
    "lang": "en",
    "outputId": "5404f7e3-919b-4e98-9411-0f92bd5248e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.8676,  0.6643,  0.2593,  1.1185,  0.2696],\n",
       "         [ 0.7057,  0.8347,  0.0582,  0.9345, -1.9410],\n",
       "         [ 0.5403,  0.0910,  0.4039,  0.9030,  0.6413],\n",
       "         [-0.3394,  1.8842,  0.5007, -0.0531, -0.5560],\n",
       "         [-0.2614,  1.5208, -0.6705, -0.1655,  1.2834],\n",
       "         [-2.4897,  2.7110, -1.1815, -0.7080,  1.6242],\n",
       "         [-0.9460,  1.5618,  0.5211, -0.8363, -0.0518],\n",
       "         [ 0.8009, -0.5986, -0.7992, -2.3112,  0.4973],\n",
       "         [ 2.0598, -1.4415,  0.3460, -0.9174,  1.1309],\n",
       "         [ 2.8127,  0.3135,  0.1889, -2.2991,  0.7678],\n",
       "         [-0.9640, -1.3251, -0.1968,  0.6444, -0.4139],\n",
       "         [ 1.8654,  0.6214, -2.1076, -0.1893, -0.2831],\n",
       "         [-0.1021,  0.3817,  0.8964,  0.6160, -0.5837],\n",
       "         [ 1.9835, -0.3968,  0.1149,  1.7424, -1.0732],\n",
       "         [ 1.4446, -0.2759,  0.4274, -1.1219, -1.3957],\n",
       "         [-0.7854,  2.6235,  0.0621, -0.3806,  0.2862],\n",
       "         [ 0.0734, -0.2134,  1.2685, -2.3063,  1.1769],\n",
       "         [-1.4079,  0.6464,  0.2431, -1.2335,  1.2699],\n",
       "         [-1.5812,  0.0592,  0.4769,  1.1063,  0.6159],\n",
       "         [ 0.3695,  0.6389, -3.2011,  2.5583, -0.7280],\n",
       "         [-2.1890, -0.3977, -0.2311,  0.4866,  1.0263],\n",
       "         [ 0.1504,  1.7677,  0.0668, -1.5771, -1.0957]], requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creando una tabla de embedding para nuestras palabras\n",
    "embedding_dim = 5\n",
    "embeds = nn.Embedding(len(vocabulary), embedding_dim)\n",
    "\n",
    "# Imprimiendo los parámetros en nuestra tabla de embedding\n",
    "list(embeds.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Para obtener el embedding de la palabra para una palabra en nuestro vocabulario, todo lo que tenemos que hacer es crear un tensor de búsqueda. El tensor de búsqueda es solo un tensor que contiene el índice que queremos buscar. La clase `nn.Embedding` espera un tensor de índices que sea del tipo `Long` Tensor, por lo que debemos crear nuestro tensor en consecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:55:18.168568Z",
     "start_time": "2022-02-28T12:55:18.163797Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkldmcepjfh_",
    "outputId": "b9e24c31-547d-41e5-9509-fb9e9777cd01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9835, -0.3968,  0.1149,  1.7424, -1.0732],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtiene el embedding para la palabra paris\n",
    "index = word_to_ix[\"paris\"]\n",
    "index_tensor = torch.tensor(index, dtype=torch.long)\n",
    "paris_embed = embeds(index_tensor)\n",
    "paris_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T12:55:26.937443Z",
     "start_time": "2022-02-28T12:55:26.932027Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUsdwBOxm6B4",
    "lang": "en",
    "outputId": "5b8cb8fe-0787-4e93-946b-ed719efcdd8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9835, -0.3968,  0.1149,  1.7424, -1.0732],\n",
       "        [-0.3394,  1.8842,  0.5007, -0.0531, -0.5560]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# También podemos obtener múltiples embeddings a la vez\n",
    "index_paris = word_to_ix[\"paris\"]\n",
    "index_ankara = word_to_ix[\"ankara\"]\n",
    "indices = [index_paris, index_ankara]\n",
    "indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
    "embeddings = embeds(indices_tensor)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Por lo general, definimos la capa de embedding como parte de nuestro modelo, que veremos en las secciones posteriores de nuestro cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:21:28.900312Z",
     "start_time": "2022-02-28T13:21:28.892271Z"
    },
    "id": "OkvvVlo4jgFm",
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "def custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # Divide nuestro batch en muestras de entrenamiento (x) y etiquetas (y)\n",
    "  # Estamos convirtiendo nuestra x e y en tensores porque el método nn.utils.rnn.pad_secuence\n",
    "  # espera tensores. Esto también es útil ya que nuestro modelo estará esperando tensores como\n",
    "  # entradas.\n",
    "  x, y = zip(*batch)\n",
    "\n",
    "  # Ahora necesitamos rellenar las ventanas de nuestrass muestras de entrenamiento.\n",
    "  # Ya hemos definido una función para manejar el relleno de la ventana. Lo incluimos aquí\n",
    "  # de nuevo para que todo está en un solo lugar.\n",
    "  def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "    window = [pad_token] * window_size\n",
    "    return window + sentence + window\n",
    "\n",
    "  # Rellena las muestras de entrenamiento\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "\n",
    "  # Ahora necesitamos convertir las palabras de nuestras muestras de entrenamiento a índices.\n",
    "  # Estamos copiando la función definida anteriormente por el mismo motivo anterior.\n",
    "  def convert_tokens_to_indices(sentence, word_to_ix):\n",
    "    return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "  # Convierte las muestras de entrenamiento a indices.\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # Ahora rellenaremos las muestras para que las longitudes de todas las muestras en\n",
    "  # un batch sean iguales, lo que permite realizar operaciones matriciales.\n",
    "  # Establecemos el parámetro batch_first en True para que la matriz devuelta tenga\n",
    "  # como la primera dimensión el batch.\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "\n",
    "\n",
    "  # la función pad_sequence espera que la entrada sea un tensor, por lo que convertimos x en uno\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # También rellenaremos las etiquetas. Antes de hacerlo, guardaremos el número\n",
    "  # de etiquetas para que sepamos cuantas palabras existieron en cada ejemplo.\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "  # Ahora estamos listos para devolver nuestras variables. El orden en que devolvemos\n",
    "  #  nuestras variables coincidirá con el orden en que los leemos en nuestro ciclo de entrenamiento.\n",
    "  return x_padded, y_padded, lenghts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Esta función parece larga, pero realmente no tiene por qué serlo. Veamos una versión alternativa a continuación, en donde eliminamos las declaraciones y comentarios de funciones adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:21:33.159405Z",
     "start_time": "2022-02-28T13:21:33.153974Z"
    },
    "id": "dZfcmAJXbLcq"
   },
   "outputs": [],
   "source": [
    "def _custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # preparando los puntos de datos\n",
    "  x, y = zip(*batch)  \n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # rellena x tal que todas las muestras en el batch tengan el mismo tamano\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # Rellena \"y\" y guarda la longitud\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "  return x_padded, y_padded, lenghts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ahora, podemos ver el `DataLoader` en acción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:27:44.710065Z",
     "start_time": "2022-02-28T13:27:44.691587Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfB0JKL2vZ6p",
    "lang": "en",
    "outputId": "663b5215-01b3-475f-edb6-ad29186a967c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Batched Input:\n",
      "tensor([[ 0,  0, 21, 20,  9,  5,  0,  0,  0],\n",
      "        [ 0,  0,  8, 14, 10,  7,  4,  0,  0]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]])\n",
      "Batched Lengths:\n",
      "tensor([4, 5])\n",
      "\n",
      "Iteration 1\n",
      "Batched Input:\n",
      "tensor([[ 0,  0, 11,  6,  7, 17, 10,  3,  0,  0],\n",
      "        [ 0,  0, 12, 15, 18,  2, 13,  0,  0,  0]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0]])\n",
      "Batched Lengths:\n",
      "tensor([6, 5])\n",
      "\n",
      "Iteration 2\n",
      "Batched Input:\n",
      "tensor([[ 0,  0,  8, 19,  7, 16,  0,  0]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 1]])\n",
      "Batched Lengths:\n",
      "tensor([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parámetros a pasar al DataLoader\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instancia el DataLoader\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Va a traves de un ciclo\n",
    "counter = 0\n",
    "for batched_x, batched_y, batched_lengths in loader:\n",
    "  print(f\"Iteration {counter}\")\n",
    "  print(\"Batched Input:\")\n",
    "  print(batched_x)\n",
    "  print(\"Batched Labels:\")\n",
    "  print(batched_y)\n",
    "  print(\"Batched Lengths:\")\n",
    "  print(batched_lengths)\n",
    "  print(\"\")\n",
    "  counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Los tensores de entrada por batch que vimos antes se pasarán a nuestro modelo. Por otro lado, comenzamos diciendo que nuestro modelo será un clasificador de ventanas de palabras. Por la forma en que nuestros tensores de entrada están formateados actualmente, tenemos todas las palabras en una sentencia en un punto de datos. Cuando pasamos esta entrada a nuestro modelo, éste necesita crear las ventanas para cada palabra, hacer una predicción sobre si la palabra central es una `UBICACIÓN` o no, para cada ventana, juntar las predicciones y volver a hacerlo.\n",
    "\n",
    "Podríamos evitar este problema si formateamos nuestros datos dividiéndolos en ventanas de antemano. En este ejemplo, en cambio, veremos cómo nuestro modelo se ocupa del formateo.\n",
    "\n",
    "Dado que nuestro `window_size` es `N`, queremos que nuestro modelo haga una predicción sobre cada `2N+1` tokens. Es decir, si tenemos una entrada con `9` tokens y un `window_size` de `2`, queremos que nuestro modelo devuelva `5` predicciones. Esto tiene sentido porque antes de rellenarlo con `2` tokens en cada lado, nuestra entrada también tenía \"5\" tokens.\n",
    "\n",
    "Podemos crear estas ventanas usando bucles for, pero hay una alternativa más rápida a `PyTorch`, que es el método `unfold(dimension, size, step)`. Podemos crear las ventanas que necesitamos usando este método de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:27:50.764906Z",
     "start_time": "2022-02-28T13:27:50.754375Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMZu-pxLVxHQ",
    "outputId": "2bff1c6a-62f5-46ab-e9d4-282ba405db6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: \n",
      "tensor([[ 0,  0,  8, 19,  7, 16,  0,  0]])\n",
      "\n",
      "Windows: \n",
      "tensor([[[ 0,  0,  8, 19,  7],\n",
      "         [ 0,  8, 19,  7, 16],\n",
      "         [ 8, 19,  7, 16,  0],\n",
      "         [19,  7, 16,  0,  0]]])\n"
     ]
    }
   ],
   "source": [
    "# muestra el tensor original\n",
    "print(f\"Original Tensor: \")\n",
    "print(batched_x)\n",
    "print(\"\")\n",
    "\n",
    "# Crea los 2 * 2 + 1 chunkstrozos\n",
    "chunk = batched_x.unfold(1, window_size*2 + 1, 1)\n",
    "print(f\"Windows: \")\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "Ahora que hemos preparado nuestro datos, estamos listos para construir nuestro modelo. Lo haremos a través de la creación de una clase que hereda de la clase `nn.Module` (ya lo hemos visto con la regresión logística y la MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:45:57.599508Z",
     "start_time": "2022-02-28T13:45:57.589397Z"
    },
    "id": "JLTU4h76NLYm"
   },
   "outputs": [],
   "source": [
    "class WordWindowClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, hyperparameters, vocab_size, pad_ix=0):\n",
    "    super(WordWindowClassifier, self).__init__()\n",
    "    \n",
    "    \"\"\" Instancia las variabless \"\"\"\n",
    "    self.window_size = hyperparameters[\"window_size\"]\n",
    "    self.embed_dim = hyperparameters[\"embed_dim\"]\n",
    "    self.hidden_dim = hyperparameters[\"hidden_dim\"]\n",
    "    self.freeze_embeddings = hyperparameters[\"freeze_embeddings\"]\n",
    "\n",
    "    \"\"\" Capa de Embedding      \n",
    "    Toma un tensor que contiene los índices de los embeddings y devuelve los embeddings\n",
    "    correspondientes. La salida es de dimensión (número_de_índices * dimension_embedding).\n",
    "\n",
    "     Si freeze_embeddings es True, configura los parámetros de la capa de embedding para que sean\n",
    "     no entrenables. Esto es útil si solo queremos cambiar los parámetros que no sean de los embeddings.\n",
    "\n",
    "    \"\"\"\n",
    "    self.embeds = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_ix)\n",
    "    if self.freeze_embeddings:\n",
    "      self.embed_layer.weight.requires_grad = False\n",
    "\n",
    "    \"\"\" Capa Oculta\n",
    "    \"\"\"\n",
    "    full_window_size = 2 * window_size + 1\n",
    "    self.hidden_layer = nn.Sequential(\n",
    "      nn.Linear(full_window_size * self.embed_dim, self.hidden_dim), \n",
    "      nn.Tanh()\n",
    "    )\n",
    "\n",
    "    \"\"\" Caba de salida\n",
    "    \"\"\"\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    \"\"\" Probabilidades \n",
    "    \"\"\"\n",
    "    self.probabilities = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    \"\"\"\n",
    "    Sea B:= batch_size\n",
    "        L:= longitud de la ventana de la sentencia rellenada\n",
    "        D:= self.embed_dim\n",
    "        S:= self.window_size\n",
    "        H:= self.hidden_dim\n",
    "        \n",
    "    entradas: un tensor (B, L) de los indices de los tokens\n",
    "    \"\"\"\n",
    "    B, L = inputs.size()\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Entra un tensor de tipo Long (B, L) \n",
    "    Produce un tensor de tipo Long (B, L~, S)\n",
    "    \"\"\"\n",
    "    # Primero, obtiene las ventanas de palabras para cada palabra de entrada.\n",
    "    token_windows = inputs.unfold(1, 2 * self.window_size + 1, 1)\n",
    "    _, adjusted_length, _ = token_windows.size()\n",
    "\n",
    "    # Es buena idea hacer verificaciones internas del tamaño de un tensor\n",
    "    assert token_windows.size() == (B, adjusted_length, 2 * self.window_size + 1)\n",
    "\n",
    "    \"\"\"\n",
    "    Embedding.\n",
    "    Entra un torch.LongTensor de tamano (B, L~, S) \n",
    "    Produce un (B, L~, S, D) FloatTensor.\n",
    "    \"\"\"\n",
    "    embedded_windows = self.embeds(token_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Entra un (B, L~, S, D) FloatTensor.\n",
    "    Cambia su tamano a (B, L~, S*D) FloatTensor.\n",
    "    El argumento -1  \"infiere\" ser la última dimensión segun los ejes sobrantes.\n",
    "    \"\"\"\n",
    "    embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
    "\n",
    "    \"\"\"\n",
    "    Capa 1.\n",
    "    Entra un (B, L~, S*D) FloatTensor.\n",
    "    Cambia su tamaño a un (B, L~, H) FloatTensor\n",
    "    \"\"\"\n",
    "    layer_1 = self.hidden_layer(embedded_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Capa 2\n",
    "    Entra un (B, L~, H) FloatTensor.\n",
    "    cambia su tamano a un (B, L~, 1) FloatTensor.\n",
    "    \"\"\"\n",
    "    output = self.output_layer(layer_1)\n",
    "\n",
    "    \"\"\"\n",
    "    Softmax.\n",
    "    Entra un (B, L~, 1) FloatTensor de scores de clases no normalizados.\n",
    "    Produce un (B, L~, 1) FloatTensor de scores de clases (log-)normalizados.\n",
    "    \"\"\"\n",
    "    output = self.probabilities(output)\n",
    "    output = output.view(B, -1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Ahora estamos listos para poner todo junto. Empecemos por preparar nuestros datos e inicializar nuestro modelo. Luego, podemos inicializar nuestro optimizador y definir nuestra función de loss. Esta vez, en lugar de usar una de las funciones de loss predefinidas, definiremos nuestra propia función de loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:50:59.158389Z",
     "start_time": "2022-02-28T13:50:59.144513Z"
    },
    "id": "bInu1VqjHsfj"
   },
   "outputs": [],
   "source": [
    "# Prepara los datos\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instancia el dataloader\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Inicializa el modelo\n",
    "# Es util colocar todos los hiperparamentros en un diccionario\n",
    "model_hyperparameters = {\n",
    "    \"batch_size\": 4,\n",
    "    \"window_size\": 2,\n",
    "    \"embed_dim\": 25,\n",
    "    \"hidden_dim\": 25,\n",
    "    \"freeze_embeddings\": False,\n",
    "}\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "model = WordWindowClassifier(model_hyperparameters, vocab_size)\n",
    "\n",
    "# define un optimizador\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Definir una función de pérdida, que calcula el binary cross entropy \n",
    "def loss_function(batch_outputs, batch_labels, batch_lengths):   \n",
    "    # calcula el loss para todo el batch\n",
    "    bceloss = nn.BCELoss()\n",
    "    loss = bceloss(batch_outputs, batch_labels.float())\n",
    "\n",
    "    # Reescala el loss. Recuerde que hemos utilizado longitudes para almacenar el\n",
    "    # número de palabras en cada muestra de entrenamiento\n",
    "    loss = loss / batch_lengths.sum().float()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:53:20.964908Z",
     "start_time": "2022-02-28T13:53:20.959970Z"
    },
    "id": "QL9IDgIOvHca"
   },
   "outputs": [],
   "source": [
    "# Funcion que se llamara en cada epoch\n",
    "def train_epoch(loss_function, optimizer, model, loader):\n",
    "  \n",
    "  # guarda el registro del loss para cada epoch\n",
    "  total_loss = 0\n",
    "  for batch_inputs, batch_labels, batch_lengths in loader:\n",
    "    # limpia los gradientes\n",
    "    optimizer.zero_grad()\n",
    "    # corre un forward pass\n",
    "    outputs = model.forward(batch_inputs)\n",
    "    # calcula el loss para un batch\n",
    "    loss = loss_function(outputs, batch_labels, batch_lengths)\n",
    "    # Calcula los gradientes\n",
    "    loss.backward()\n",
    "    # Actualiza los parámetros\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  return total_loss\n",
    "\n",
    "\n",
    "# Función que contiene el loop principal\n",
    "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
    "\n",
    "  # Itera a traves de cada epoch y llama la funcion de train_epoch function\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, loader)\n",
    "    if epoch % 100 == 0: print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:53:28.426400Z",
     "start_time": "2022-02-28T13:53:27.231079Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kav8kwVBJ6XW",
    "outputId": "28dafd55-14b7-4a21-b7d0-fd8cde687fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3098483607172966\n",
      "0.2317947894334793\n",
      "0.19447655603289604\n",
      "0.1381285935640335\n",
      "0.09531340189278126\n",
      "0.07393439672887325\n",
      "0.056153520941734314\n",
      "0.0458388514816761\n",
      "0.0358200604096055\n",
      "0.03131720330566168\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "train(loss_function, optimizer, model, loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-k7Pav4LdQJ"
   },
   "source": [
    "### Predicción\n",
    "\n",
    "Veamos qué tan bien nuestro modelo hace predicciones. Podemos comenzar creando nuestros datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:54:23.027939Z",
     "start_time": "2022-02-28T13:54:23.023633Z"
    },
    "id": "-v5X69a2Lkbm"
   },
   "outputs": [],
   "source": [
    "# Creando una sentencia de prueba\n",
    "test_corpus = [\"Ella viene de Paris\"]\n",
    "test_sentences = [s.lower().split() for s in test_corpus]\n",
    "test_labels = [[0, 0, 0, 1]]\n",
    "\n",
    "# Crea un dataloader de prueba\n",
    "test_data = list(zip(test_sentences, test_labels))\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=2, word_to_ix=word_to_ix)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=False, \n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:54:43.051656Z",
     "start_time": "2022-02-28T13:54:43.047193Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGYn8CAoMTjX",
    "outputId": "e63fce32-9d1d-4a80-a2f9-dd555928f852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1]])\n",
      "tensor([[0.0673, 0.0535, 0.0533, 0.9557]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for test_instance, labels, _ in test_loader:\n",
    "  outputs = model.forward(test_instance)\n",
    "  print(labels)\n",
    "  print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T13:54:48.755212Z",
     "start_time": "2022-02-28T13:54:48.750982Z"
    },
    "id": "iebrU4ZibVIR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['nosotros', 'siempre', 'venimos', 'a', 'paris'], [0, 0, 0, 0, 1]),\n",
       " (['el', 'profesor', 'es', 'de', 'australia'], [0, 0, 0, 0, 1]),\n",
       " (['yo', 'vivo', 'en', 'bogota'], [0, 0, 0, 1]),\n",
       " (['el', 'viene', 'de', 'taiwan'], [0, 0, 0, 1]),\n",
       " (['la', 'capital', 'de', 'turquia', 'es', 'ankara'], [0, 0, 0, 1, 0, 1])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio \n",
    "Cree unas frases con sus respectivas etiquetas para diferentes tipos de palabras: por ejemplo: nombre, verbo, lugar y otros, y realice un proceso simila al anterior donde clasificara las palabras usando ventanas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas pruebas para entender más acerca de las dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:25:29.557855Z",
     "start_time": "2022-02-28T17:25:29.554154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1415, 0.2237, 0.0396],\n",
      "        [0.7304, 0.7470, 0.2466],\n",
      "        [0.4285, 0.8204, 0.5544],\n",
      "        [0.7045, 0.5630, 0.1440]])\n"
     ]
    }
   ],
   "source": [
    "w = torch.rand(4,3)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7057, 6.4309, 2.7716])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4],dtype=torch.float)\n",
    "x @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.6487, 11.4413,  5.3579],\n",
       "        [12.8645, 15.7308,  7.3485],\n",
       "        [12.8723, 14.3559,  6.0363],\n",
       "        [ 4.1514,  4.9318,  2.0086],\n",
       "        [12.4391, 15.4657,  6.8483],\n",
       "        [ 8.3176,  9.1935,  3.1947],\n",
       "        [11.0160, 11.2565,  3.3980]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randint(1,10,(7,4), dtype=torch.float)\n",
    "X @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 4., 4., 5.],\n",
      "         [1., 7., 3., 4.],\n",
      "         [3., 2., 6., 7.],\n",
      "         [3., 7., 6., 1.],\n",
      "         [4., 5., 5., 3.],\n",
      "         [5., 7., 4., 8.],\n",
      "         [7., 4., 8., 2.]],\n",
      "\n",
      "        [[1., 3., 6., 5.],\n",
      "         [8., 4., 4., 2.],\n",
      "         [5., 6., 5., 1.],\n",
      "         [3., 1., 1., 9.],\n",
      "         [3., 3., 3., 1.],\n",
      "         [1., 7., 3., 4.],\n",
      "         [3., 5., 7., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "X_big = X = torch.randint(1,10,(2,7,4), dtype=torch.float)\n",
    "print(X_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.5826,  9.7557,  4.0423],\n",
       "         [ 9.3578, 10.1659,  4.0044],\n",
       "         [ 9.3877, 11.0286,  4.9458],\n",
       "         [ 8.8130, 11.3854,  5.3148],\n",
       "         [ 8.4741, 10.4207,  4.5949],\n",
       "         [13.1703, 14.1331,  5.2930],\n",
       "         [ 8.7493, 12.2430,  5.9863]],\n",
       "\n",
       "        [[ 8.4261, 10.2022,  4.8252],\n",
       "         [ 7.1768,  9.1850,  3.8085],\n",
       "         [ 7.9371, 10.2654,  4.5932],\n",
       "         [ 7.9237,  7.3055,  2.2153],\n",
       "         [ 4.6058,  5.9362,  2.6656],\n",
       "         [ 9.3578, 10.1659,  4.0044],\n",
       "         [ 9.8940, 12.4009,  5.8079]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_big @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[40.2208],\n",
      "         [41.7027],\n",
      "         [46.2821],\n",
      "         [47.5283],\n",
      "         [43.1003],\n",
      "         [57.3155],\n",
      "         [51.1943]],\n",
      "\n",
      "        [[43.3060],\n",
      "         [36.9725],\n",
      "         [42.2474],\n",
      "         [29.1808],\n",
      "         [24.4749],\n",
      "         [41.7027],\n",
      "         [52.1196]]])\n"
     ]
    }
   ],
   "source": [
    "new = (X_big @ w) @ torch.tensor([1.,2.,3.]).view(-1,1)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40.2208, 41.7027, 46.2821, 47.5283, 43.1003, 57.3155, 51.1943],\n",
       "        [43.3060, 36.9725, 42.2474, 29.1808, 24.4749, 41.7027, 52.1196]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.view(2,-1) # new.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución punto 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestros datos sin procesar, que consisten en oraciones\n",
    "# Oraciones obtenidas de https://blogs.uoc.edu/humanitats/es/frases-sobre-arte-dia-mundial-del-arte/\n",
    "corpus = [\n",
    "          \"El arte es lo que dejas salir\",\n",
    "\"El arte no reproduce aquello que es visible sino que hace visible aquello que no siempre lo es.\",\n",
    "\"El arte tiene la bonita costumbre de echar a perder todas las teorías artísticas.\",\n",
    "\"El arte es una garantía de cordura.\",\n",
    "\"Aprende las reglas como un profesional, para que puedas romperlas como un artista.\",\n",
    "\"Nunca pinto sueños o pesadillas. Pinto mi propia realidad.\",\n",
    "\"No tengas miedo de la perfección, nunca la alcanzarás.\",\n",
    "\"El arte deriva de un deseo de la persona para comunicarse con otro.\",\n",
    "\"El papel de las artes representativas\",\n",
    "\"Quería comenzar una revolución, usar el arte para construir el tipo de sociedad que yo misma imaginaba.\",\n",
    "\"Veo el arte y la literatura como un posible ensanchamiento de horizontes hacia la libertad.\",\n",
    "\"Entiendo que un artista es alguien que, entre el silencio de los demás, utiliza su voz para decir algo, y que tiene la obligación que esto no sea algo inútil sino algo que dé un servicio a los hombres.\",\n",
    "\"El arte está ligado a lo que todavía no se crea.\",\n",
    "\"Hay a nuestro alrededor emociones muy bellas y en el arte, donde están las más intensas, no acepto la mediocridad. Hay arte, no arte decorativo. El arte es algo riguroso, el arte decorativo no lo es, es superficial, alborotador.\",\n",
    "\"A veces pienso que lo peor es la actual ‘mundanalidad’ de toda la escena [artística]. Es la cosa más engañosa, corruptora y transitoria, llena de patadas y diversión, pero tan poco que ver con lo que realmente se trata. Tiene que ver con nuestro tiempo, un pacto desesperado sobre el poder de la inmediatez. Pero me siento cada vez menos preocupado por esto como un problema. ¿Y qué? No hay amenaza.\",\n",
    "\"Todo mi trabajo sigue como un péndulo; parece regresar a algo en lo que estuve involucrado anteriormente, o se mueve entre la horizontalidad y la verticalidad, la circularidad o una combinación de ellas. Para mí, supongo que el cambio es la única constante.\",\n",
    "\"Es mi deber expresar los sufrimientos de las personas, los sufrimientos que nunca terminan y que son tan grandes como las montañas.\",\n",
    "\"(La performance es como) el arte que combina el tiempo y el espacio con la presencia de un público que no es un mero espectador, sino que también participa de la acción.\",\n",
    "\"No hay arte sin transformación.\",\n",
    "\"El arte nos atrae solamente cuando revela en nosotros secretos.\",\n",
    "\"Todo arte es autobiográfico.\",\n",
    "\"El arte no cambia nada, el arte te cambia a ti.\",\n",
    "\"Cuando estoy haciendo arte, no tengo absolutamente responsabilidad social alguna. Es como soñar.\",\n",
    "\"La música es tu propia experiencia, tus propios pensamientos, tu sabiduría. Si no la vives no va a salir de tu cuerno. Te dicen que hay una línea limitadora para la música. Pero no hay fronteras para el arte.\",\n",
    "\"Todo buen arte es una indiscreción.\",\n",
    "\"La inspiración es trabajar todos los días.\",\n",
    "\"El arte es lo que resiste: resiste a la muerte, a la servidumbre, a la infamia, a la vergüenza.\",\n",
    "\"Nada es más nocivo para la creatividad que el furor de la inspiración.\",\n",
    "\"El papel del artista es hacer preguntas, no responderlas.\",\n",
    "\"La arquitectura es música congelada.\",\n",
    "\"El hablar de estas cosas y el tratar de comprender su naturaleza y, una vez comprendida, el tratar lentamente, humildemente, constantemente de expresar, de exprimir de nuevo, de la tierra grosera o de lo que la tierra produce, de la forma, del sonido y del color (que son las puertas de la cárcel del alma) una imagen de la belleza que hemos llegado a comprender: eso es el arte.\",\n",
    "\"El arte parece ser el empeño por descifrar o perseguir la huella dejada por una forma perdida de existencia.\",\n",
    "\"La belleza artística no consiste en representar una cosa bella, sino en la bella representación de una cosa.\",\n",
    "\"El objetivo del arte no es representar la apariencia externa de las cosas, sino su significado interior.\",\n",
    "\"La observación de la naturaleza y la meditación han generado el arte.\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['el', 'arte', 'es', 'lo', 'que', 'dejas', 'salir'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'no',\n",
       "  'reproduce',\n",
       "  'aquello',\n",
       "  'que',\n",
       "  'es',\n",
       "  'visible',\n",
       "  'sino',\n",
       "  'que',\n",
       "  'hace',\n",
       "  'visible',\n",
       "  'aquello',\n",
       "  'que',\n",
       "  'no',\n",
       "  'siempre',\n",
       "  'lo',\n",
       "  'es.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'tiene',\n",
       "  'la',\n",
       "  'bonita',\n",
       "  'costumbre',\n",
       "  'de',\n",
       "  'echar',\n",
       "  'a',\n",
       "  'perder',\n",
       "  'todas',\n",
       "  'las',\n",
       "  'teorias',\n",
       "  'artisticas.'],\n",
       " ['el', 'arte', 'es', 'una', 'garantia', 'de', 'cordura.'],\n",
       " ['aprende',\n",
       "  'las',\n",
       "  'reglas',\n",
       "  'como',\n",
       "  'un',\n",
       "  'profesional,',\n",
       "  'para',\n",
       "  'que',\n",
       "  'puedas',\n",
       "  'romperlas',\n",
       "  'como',\n",
       "  'un',\n",
       "  'artista.'],\n",
       " ['nunca',\n",
       "  'pinto',\n",
       "  'sueños',\n",
       "  'o',\n",
       "  'pesadillas.',\n",
       "  'pinto',\n",
       "  'mi',\n",
       "  'propia',\n",
       "  'realidad.'],\n",
       " ['no',\n",
       "  'tengas',\n",
       "  'miedo',\n",
       "  'de',\n",
       "  'la',\n",
       "  'perfeccion,',\n",
       "  'nunca',\n",
       "  'la',\n",
       "  'alcanzaras.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'deriva',\n",
       "  'de',\n",
       "  'un',\n",
       "  'deseo',\n",
       "  'de',\n",
       "  'la',\n",
       "  'persona',\n",
       "  'para',\n",
       "  'comunicarse',\n",
       "  'con',\n",
       "  'otro.'],\n",
       " ['el', 'papel', 'de', 'las', 'artes', 'representativas'],\n",
       " ['queria',\n",
       "  'comenzar',\n",
       "  'una',\n",
       "  'revolucion,',\n",
       "  'usar',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'para',\n",
       "  'construir',\n",
       "  'el',\n",
       "  'tipo',\n",
       "  'de',\n",
       "  'sociedad',\n",
       "  'que',\n",
       "  'yo',\n",
       "  'misma',\n",
       "  'imaginaba.'],\n",
       " ['veo',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'y',\n",
       "  'la',\n",
       "  'literatura',\n",
       "  'como',\n",
       "  'un',\n",
       "  'posible',\n",
       "  'ensanchamiento',\n",
       "  'de',\n",
       "  'horizontes',\n",
       "  'hacia',\n",
       "  'la',\n",
       "  'libertad.'],\n",
       " ['entiendo',\n",
       "  'que',\n",
       "  'un',\n",
       "  'artista',\n",
       "  'es',\n",
       "  'alguien',\n",
       "  'que,',\n",
       "  'entre',\n",
       "  'el',\n",
       "  'silencio',\n",
       "  'de',\n",
       "  'los',\n",
       "  'demas,',\n",
       "  'utiliza',\n",
       "  'su',\n",
       "  'voz',\n",
       "  'para',\n",
       "  'decir',\n",
       "  'algo,',\n",
       "  'y',\n",
       "  'que',\n",
       "  'tiene',\n",
       "  'la',\n",
       "  'obligacion',\n",
       "  'que',\n",
       "  'esto',\n",
       "  'no',\n",
       "  'sea',\n",
       "  'algo',\n",
       "  'inutil',\n",
       "  'sino',\n",
       "  'algo',\n",
       "  'que',\n",
       "  'de',\n",
       "  'un',\n",
       "  'servicio',\n",
       "  'a',\n",
       "  'los',\n",
       "  'hombres.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'esta',\n",
       "  'ligado',\n",
       "  'a',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'todavia',\n",
       "  'no',\n",
       "  'se',\n",
       "  'crea.'],\n",
       " ['hay',\n",
       "  'a',\n",
       "  'nuestro',\n",
       "  'alrededor',\n",
       "  'emociones',\n",
       "  'muy',\n",
       "  'bellas',\n",
       "  'y',\n",
       "  'en',\n",
       "  'el',\n",
       "  'arte,',\n",
       "  'donde',\n",
       "  'estan',\n",
       "  'las',\n",
       "  'mas',\n",
       "  'intensas,',\n",
       "  'no',\n",
       "  'acepto',\n",
       "  'la',\n",
       "  'mediocridad.',\n",
       "  'hay',\n",
       "  'arte,',\n",
       "  'no',\n",
       "  'arte',\n",
       "  'decorativo.',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'es',\n",
       "  'algo',\n",
       "  'riguroso,',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'decorativo',\n",
       "  'no',\n",
       "  'lo',\n",
       "  'es,',\n",
       "  'es',\n",
       "  'superficial,',\n",
       "  'alborotador.'],\n",
       " ['a',\n",
       "  'veces',\n",
       "  'pienso',\n",
       "  'que',\n",
       "  'lo',\n",
       "  'peor',\n",
       "  'es',\n",
       "  'la',\n",
       "  'actual',\n",
       "  '‘mundanalidad’',\n",
       "  'de',\n",
       "  'toda',\n",
       "  'la',\n",
       "  'escena',\n",
       "  '[artistica].',\n",
       "  'es',\n",
       "  'la',\n",
       "  'cosa',\n",
       "  'mas',\n",
       "  'engañosa,',\n",
       "  'corruptora',\n",
       "  'y',\n",
       "  'transitoria,',\n",
       "  'llena',\n",
       "  'de',\n",
       "  'patadas',\n",
       "  'y',\n",
       "  'diversion,',\n",
       "  'pero',\n",
       "  'tan',\n",
       "  'poco',\n",
       "  'que',\n",
       "  'ver',\n",
       "  'con',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'realmente',\n",
       "  'se',\n",
       "  'trata.',\n",
       "  'tiene',\n",
       "  'que',\n",
       "  'ver',\n",
       "  'con',\n",
       "  'nuestro',\n",
       "  'tiempo,',\n",
       "  'un',\n",
       "  'pacto',\n",
       "  'desesperado',\n",
       "  'sobre',\n",
       "  'el',\n",
       "  'poder',\n",
       "  'de',\n",
       "  'la',\n",
       "  'inmediatez.',\n",
       "  'pero',\n",
       "  'me',\n",
       "  'siento',\n",
       "  'cada',\n",
       "  'vez',\n",
       "  'menos',\n",
       "  'preocupado',\n",
       "  'por',\n",
       "  'esto',\n",
       "  'como',\n",
       "  'un',\n",
       "  'problema.',\n",
       "  '¿y',\n",
       "  'que?',\n",
       "  'no',\n",
       "  'hay',\n",
       "  'amenaza.'],\n",
       " ['todo',\n",
       "  'mi',\n",
       "  'trabajo',\n",
       "  'sigue',\n",
       "  'como',\n",
       "  'un',\n",
       "  'pendulo;',\n",
       "  'parece',\n",
       "  'regresar',\n",
       "  'a',\n",
       "  'algo',\n",
       "  'en',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'estuve',\n",
       "  'involucrado',\n",
       "  'anteriormente,',\n",
       "  'o',\n",
       "  'se',\n",
       "  'mueve',\n",
       "  'entre',\n",
       "  'la',\n",
       "  'horizontalidad',\n",
       "  'y',\n",
       "  'la',\n",
       "  'verticalidad,',\n",
       "  'la',\n",
       "  'circularidad',\n",
       "  'o',\n",
       "  'una',\n",
       "  'combinacion',\n",
       "  'de',\n",
       "  'ellas.',\n",
       "  'para',\n",
       "  'mi,',\n",
       "  'supongo',\n",
       "  'que',\n",
       "  'el',\n",
       "  'cambio',\n",
       "  'es',\n",
       "  'la',\n",
       "  'unica',\n",
       "  'constante.'],\n",
       " ['es',\n",
       "  'mi',\n",
       "  'deber',\n",
       "  'expresar',\n",
       "  'los',\n",
       "  'sufrimientos',\n",
       "  'de',\n",
       "  'las',\n",
       "  'personas,',\n",
       "  'los',\n",
       "  'sufrimientos',\n",
       "  'que',\n",
       "  'nunca',\n",
       "  'terminan',\n",
       "  'y',\n",
       "  'que',\n",
       "  'son',\n",
       "  'tan',\n",
       "  'grandes',\n",
       "  'como',\n",
       "  'las',\n",
       "  'montañas.'],\n",
       " ['(la',\n",
       "  'performance',\n",
       "  'es',\n",
       "  'como)',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'que',\n",
       "  'combina',\n",
       "  'el',\n",
       "  'tiempo',\n",
       "  'y',\n",
       "  'el',\n",
       "  'espacio',\n",
       "  'con',\n",
       "  'la',\n",
       "  'presencia',\n",
       "  'de',\n",
       "  'un',\n",
       "  'publico',\n",
       "  'que',\n",
       "  'no',\n",
       "  'es',\n",
       "  'un',\n",
       "  'mero',\n",
       "  'espectador,',\n",
       "  'sino',\n",
       "  'que',\n",
       "  'tambien',\n",
       "  'participa',\n",
       "  'de',\n",
       "  'la',\n",
       "  'accion.'],\n",
       " ['no', 'hay', 'arte', 'sin', 'transformacion.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'nos',\n",
       "  'atrae',\n",
       "  'solamente',\n",
       "  'cuando',\n",
       "  'revela',\n",
       "  'en',\n",
       "  'nosotros',\n",
       "  'secretos.'],\n",
       " ['todo', 'arte', 'es', 'autobiografico.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'no',\n",
       "  'cambia',\n",
       "  'nada,',\n",
       "  'el',\n",
       "  'arte',\n",
       "  'te',\n",
       "  'cambia',\n",
       "  'a',\n",
       "  'ti.'],\n",
       " ['cuando',\n",
       "  'estoy',\n",
       "  'haciendo',\n",
       "  'arte,',\n",
       "  'no',\n",
       "  'tengo',\n",
       "  'absolutamente',\n",
       "  'responsabilidad',\n",
       "  'social',\n",
       "  'alguna.',\n",
       "  'es',\n",
       "  'como',\n",
       "  'soñar.'],\n",
       " ['la',\n",
       "  'musica',\n",
       "  'es',\n",
       "  'tu',\n",
       "  'propia',\n",
       "  'experiencia,',\n",
       "  'tus',\n",
       "  'propios',\n",
       "  'pensamientos,',\n",
       "  'tu',\n",
       "  'sabiduria.',\n",
       "  'si',\n",
       "  'no',\n",
       "  'la',\n",
       "  'vives',\n",
       "  'no',\n",
       "  'va',\n",
       "  'a',\n",
       "  'salir',\n",
       "  'de',\n",
       "  'tu',\n",
       "  'cuerno.',\n",
       "  'te',\n",
       "  'dicen',\n",
       "  'que',\n",
       "  'hay',\n",
       "  'una',\n",
       "  'linea',\n",
       "  'limitadora',\n",
       "  'para',\n",
       "  'la',\n",
       "  'musica.',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'hay',\n",
       "  'fronteras',\n",
       "  'para',\n",
       "  'el',\n",
       "  'arte.'],\n",
       " ['todo', 'buen', 'arte', 'es', 'una', 'indiscrecion.'],\n",
       " ['la', 'inspiracion', 'es', 'trabajar', 'todos', 'los', 'dias.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'es',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'resiste:',\n",
       "  'resiste',\n",
       "  'a',\n",
       "  'la',\n",
       "  'muerte,',\n",
       "  'a',\n",
       "  'la',\n",
       "  'servidumbre,',\n",
       "  'a',\n",
       "  'la',\n",
       "  'infamia,',\n",
       "  'a',\n",
       "  'la',\n",
       "  'verguenza.'],\n",
       " ['nada',\n",
       "  'es',\n",
       "  'mas',\n",
       "  'nocivo',\n",
       "  'para',\n",
       "  'la',\n",
       "  'creatividad',\n",
       "  'que',\n",
       "  'el',\n",
       "  'furor',\n",
       "  'de',\n",
       "  'la',\n",
       "  'inspiracion.'],\n",
       " ['el',\n",
       "  'papel',\n",
       "  'del',\n",
       "  'artista',\n",
       "  'es',\n",
       "  'hacer',\n",
       "  'preguntas,',\n",
       "  'no',\n",
       "  'responderlas.'],\n",
       " ['la', 'arquitectura', 'es', 'musica', 'congelada.'],\n",
       " ['el',\n",
       "  'hablar',\n",
       "  'de',\n",
       "  'estas',\n",
       "  'cosas',\n",
       "  'y',\n",
       "  'el',\n",
       "  'tratar',\n",
       "  'de',\n",
       "  'comprender',\n",
       "  'su',\n",
       "  'naturaleza',\n",
       "  'y,',\n",
       "  'una',\n",
       "  'vez',\n",
       "  'comprendida,',\n",
       "  'el',\n",
       "  'tratar',\n",
       "  'lentamente,',\n",
       "  'humildemente,',\n",
       "  'constantemente',\n",
       "  'de',\n",
       "  'expresar,',\n",
       "  'de',\n",
       "  'exprimir',\n",
       "  'de',\n",
       "  'nuevo,',\n",
       "  'de',\n",
       "  'la',\n",
       "  'tierra',\n",
       "  'grosera',\n",
       "  'o',\n",
       "  'de',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'la',\n",
       "  'tierra',\n",
       "  'produce,',\n",
       "  'de',\n",
       "  'la',\n",
       "  'forma,',\n",
       "  'del',\n",
       "  'sonido',\n",
       "  'y',\n",
       "  'del',\n",
       "  'color',\n",
       "  '(que',\n",
       "  'son',\n",
       "  'las',\n",
       "  'puertas',\n",
       "  'de',\n",
       "  'la',\n",
       "  'carcel',\n",
       "  'del',\n",
       "  'alma)',\n",
       "  'una',\n",
       "  'imagen',\n",
       "  'de',\n",
       "  'la',\n",
       "  'belleza',\n",
       "  'que',\n",
       "  'hemos',\n",
       "  'llegado',\n",
       "  'a',\n",
       "  'comprender:',\n",
       "  'eso',\n",
       "  'es',\n",
       "  'el',\n",
       "  'arte.'],\n",
       " ['el',\n",
       "  'arte',\n",
       "  'parece',\n",
       "  'ser',\n",
       "  'el',\n",
       "  'empeño',\n",
       "  'por',\n",
       "  'descifrar',\n",
       "  'o',\n",
       "  'perseguir',\n",
       "  'la',\n",
       "  'huella',\n",
       "  'dejada',\n",
       "  'por',\n",
       "  'una',\n",
       "  'forma',\n",
       "  'perdida',\n",
       "  'de',\n",
       "  'existencia.'],\n",
       " ['la',\n",
       "  'belleza',\n",
       "  'artistica',\n",
       "  'no',\n",
       "  'consiste',\n",
       "  'en',\n",
       "  'representar',\n",
       "  'una',\n",
       "  'cosa',\n",
       "  'bella,',\n",
       "  'sino',\n",
       "  'en',\n",
       "  'la',\n",
       "  'bella',\n",
       "  'representacion',\n",
       "  'de',\n",
       "  'una',\n",
       "  'cosa.'],\n",
       " ['el',\n",
       "  'objetivo',\n",
       "  'del',\n",
       "  'arte',\n",
       "  'no',\n",
       "  'es',\n",
       "  'representar',\n",
       "  'la',\n",
       "  'apariencia',\n",
       "  'externa',\n",
       "  'de',\n",
       "  'las',\n",
       "  'cosas,',\n",
       "  'sino',\n",
       "  'su',\n",
       "  'significado',\n",
       "  'interior.'],\n",
       " ['la',\n",
       "  'observacion',\n",
       "  'de',\n",
       "  'la',\n",
       "  'naturaleza',\n",
       "  'y',\n",
       "  'la',\n",
       "  'meditacion',\n",
       "  'han',\n",
       "  'generado',\n",
       "  'el',\n",
       "  'arte.']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanning funcitons\n",
    "def quitartildes(s):\n",
    "    # -> NFD y eliminar diacríticos\n",
    "    s = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", s), 0, re.I\n",
    "        )\n",
    "\n",
    "    # -> NFCNosotros\n",
    "    return normalize( 'NFC', s)\n",
    "\n",
    "# tokenization functions\n",
    "def preprocess_sentence(sentence):\n",
    "  return quitartildes(sentence).lower().split()\n",
    "\n",
    "#tokenise al cleanins \n",
    "train_sentences = [preprocess_sentence(sent) for sent in corpus]\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "MjySEbNHQskV"
   },
   "outputs": [],
   "source": [
    "verbos = set ([\"hacer\", 'pinto', 'revela', 'atrae', 'tratar', 'combina'])\n",
    "arte = set ([\"arte\", 'inspiracion', 'realidad', 'huella', 'bella', 'naturaleza'])\n",
    "palabras = set ([\"sabiduria\", 'vergüenza', 'emociones', 'amenaza', 'infamia', 'servidumbre', 'naturaleza', 'observacion'])\n",
    "\n",
    "validador = {\n",
    "    'verbos': (verbos, 1),\n",
    "    'arte': (arte, 2),\n",
    "    'palabras': (palabras, 3) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_cat(x = 'arte'):\n",
    "    for item_ in validador.keys():\n",
    "        if x in validador[item_][0]:\n",
    "            return validador[item_][1]\n",
    "    return 0\n",
    "f_cat('vergüenza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 0, 0, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0, 0, 2, 0, 0],\n",
       " [0, 2, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 2, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0, 0, 2, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       " [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nuestras etiquetas de entrenamiento\n",
    "train_labels = [[f_cat(word) for word in sent] for sent in train_sentences]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ4urW7IQskW"
   },
   "source": [
    "### Creación del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "SwwJ_fISQskW",
    "outputId": "2fe834c1-ea96-491b-d031-95b994f37ddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(la',\n",
       " '(que',\n",
       " '[artistica].',\n",
       " 'a',\n",
       " 'absolutamente',\n",
       " 'accion.',\n",
       " 'acepto',\n",
       " 'actual',\n",
       " 'alborotador.',\n",
       " 'alcanzaras.',\n",
       " 'algo',\n",
       " 'algo,',\n",
       " 'alguien',\n",
       " 'alguna.',\n",
       " 'alma)',\n",
       " 'alrededor',\n",
       " 'amenaza.',\n",
       " 'anteriormente,',\n",
       " 'apariencia',\n",
       " 'aprende',\n",
       " 'aquello',\n",
       " 'arquitectura',\n",
       " 'arte',\n",
       " 'arte,',\n",
       " 'arte.',\n",
       " 'artes',\n",
       " 'artista',\n",
       " 'artista.',\n",
       " 'artistica',\n",
       " 'artisticas.',\n",
       " 'atrae',\n",
       " 'autobiografico.',\n",
       " 'bella',\n",
       " 'bella,',\n",
       " 'bellas',\n",
       " 'belleza',\n",
       " 'bonita',\n",
       " 'buen',\n",
       " 'cada',\n",
       " 'cambia',\n",
       " 'cambio',\n",
       " 'carcel',\n",
       " 'circularidad',\n",
       " 'color',\n",
       " 'combina',\n",
       " 'combinacion',\n",
       " 'comenzar',\n",
       " 'como',\n",
       " 'como)',\n",
       " 'comprender',\n",
       " 'comprender:',\n",
       " 'comprendida,',\n",
       " 'comunicarse',\n",
       " 'con',\n",
       " 'congelada.',\n",
       " 'consiste',\n",
       " 'constante.',\n",
       " 'constantemente',\n",
       " 'construir',\n",
       " 'cordura.',\n",
       " 'corruptora',\n",
       " 'cosa',\n",
       " 'cosa.',\n",
       " 'cosas',\n",
       " 'cosas,',\n",
       " 'costumbre',\n",
       " 'crea.',\n",
       " 'creatividad',\n",
       " 'cuando',\n",
       " 'cuerno.',\n",
       " 'de',\n",
       " 'deber',\n",
       " 'decir',\n",
       " 'decorativo',\n",
       " 'decorativo.',\n",
       " 'dejada',\n",
       " 'dejas',\n",
       " 'del',\n",
       " 'demas,',\n",
       " 'deriva',\n",
       " 'descifrar',\n",
       " 'deseo',\n",
       " 'desesperado',\n",
       " 'dias.',\n",
       " 'dicen',\n",
       " 'diversion,',\n",
       " 'donde',\n",
       " 'echar',\n",
       " 'el',\n",
       " 'ellas.',\n",
       " 'emociones',\n",
       " 'empeño',\n",
       " 'en',\n",
       " 'engañosa,',\n",
       " 'ensanchamiento',\n",
       " 'entiendo',\n",
       " 'entre',\n",
       " 'es',\n",
       " 'es,',\n",
       " 'es.',\n",
       " 'escena',\n",
       " 'eso',\n",
       " 'espacio',\n",
       " 'espectador,',\n",
       " 'esta',\n",
       " 'estan',\n",
       " 'estas',\n",
       " 'esto',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'existencia.',\n",
       " 'experiencia,',\n",
       " 'expresar',\n",
       " 'expresar,',\n",
       " 'exprimir',\n",
       " 'externa',\n",
       " 'forma',\n",
       " 'forma,',\n",
       " 'fronteras',\n",
       " 'furor',\n",
       " 'garantia',\n",
       " 'generado',\n",
       " 'grandes',\n",
       " 'grosera',\n",
       " 'hablar',\n",
       " 'hace',\n",
       " 'hacer',\n",
       " 'hacia',\n",
       " 'haciendo',\n",
       " 'han',\n",
       " 'hay',\n",
       " 'hemos',\n",
       " 'hombres.',\n",
       " 'horizontalidad',\n",
       " 'horizontes',\n",
       " 'huella',\n",
       " 'humildemente,',\n",
       " 'imagen',\n",
       " 'imaginaba.',\n",
       " 'indiscrecion.',\n",
       " 'infamia,',\n",
       " 'inmediatez.',\n",
       " 'inspiracion',\n",
       " 'inspiracion.',\n",
       " 'intensas,',\n",
       " 'interior.',\n",
       " 'inutil',\n",
       " 'involucrado',\n",
       " 'la',\n",
       " 'las',\n",
       " 'lentamente,',\n",
       " 'libertad.',\n",
       " 'ligado',\n",
       " 'limitadora',\n",
       " 'linea',\n",
       " 'literatura',\n",
       " 'llegado',\n",
       " 'llena',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mediocridad.',\n",
       " 'meditacion',\n",
       " 'menos',\n",
       " 'mero',\n",
       " 'mi',\n",
       " 'mi,',\n",
       " 'miedo',\n",
       " 'misma',\n",
       " 'montañas.',\n",
       " 'muerte,',\n",
       " 'mueve',\n",
       " 'musica',\n",
       " 'musica.',\n",
       " 'muy',\n",
       " 'nada',\n",
       " 'nada,',\n",
       " 'naturaleza',\n",
       " 'no',\n",
       " 'nocivo',\n",
       " 'nos',\n",
       " 'nosotros',\n",
       " 'nuestro',\n",
       " 'nuevo,',\n",
       " 'nunca',\n",
       " 'o',\n",
       " 'objetivo',\n",
       " 'obligacion',\n",
       " 'observacion',\n",
       " 'otro.',\n",
       " 'pacto',\n",
       " 'papel',\n",
       " 'para',\n",
       " 'parece',\n",
       " 'participa',\n",
       " 'patadas',\n",
       " 'pendulo;',\n",
       " 'pensamientos,',\n",
       " 'peor',\n",
       " 'perder',\n",
       " 'perdida',\n",
       " 'perfeccion,',\n",
       " 'performance',\n",
       " 'pero',\n",
       " 'perseguir',\n",
       " 'persona',\n",
       " 'personas,',\n",
       " 'pesadillas.',\n",
       " 'pienso',\n",
       " 'pinto',\n",
       " 'poco',\n",
       " 'poder',\n",
       " 'por',\n",
       " 'posible',\n",
       " 'preguntas,',\n",
       " 'preocupado',\n",
       " 'presencia',\n",
       " 'problema.',\n",
       " 'produce,',\n",
       " 'profesional,',\n",
       " 'propia',\n",
       " 'propios',\n",
       " 'publico',\n",
       " 'puedas',\n",
       " 'puertas',\n",
       " 'que',\n",
       " 'que,',\n",
       " 'que?',\n",
       " 'queria',\n",
       " 'realidad.',\n",
       " 'realmente',\n",
       " 'reglas',\n",
       " 'regresar',\n",
       " 'representacion',\n",
       " 'representar',\n",
       " 'representativas',\n",
       " 'reproduce',\n",
       " 'resiste',\n",
       " 'resiste:',\n",
       " 'responderlas.',\n",
       " 'responsabilidad',\n",
       " 'revela',\n",
       " 'revolucion,',\n",
       " 'riguroso,',\n",
       " 'romperlas',\n",
       " 'sabiduria.',\n",
       " 'salir',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'secretos.',\n",
       " 'ser',\n",
       " 'servicio',\n",
       " 'servidumbre,',\n",
       " 'si',\n",
       " 'siempre',\n",
       " 'siento',\n",
       " 'significado',\n",
       " 'sigue',\n",
       " 'silencio',\n",
       " 'sin',\n",
       " 'sino',\n",
       " 'sobre',\n",
       " 'social',\n",
       " 'sociedad',\n",
       " 'solamente',\n",
       " 'son',\n",
       " 'sonido',\n",
       " 'soñar.',\n",
       " 'su',\n",
       " 'sueños',\n",
       " 'sufrimientos',\n",
       " 'superficial,',\n",
       " 'supongo',\n",
       " 'tambien',\n",
       " 'tan',\n",
       " 'te',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'teorias',\n",
       " 'terminan',\n",
       " 'ti.',\n",
       " 'tiempo',\n",
       " 'tiempo,',\n",
       " 'tiene',\n",
       " 'tierra',\n",
       " 'tipo',\n",
       " 'toda',\n",
       " 'todas',\n",
       " 'todavia',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'trabajar',\n",
       " 'trabajo',\n",
       " 'transformacion.',\n",
       " 'transitoria,',\n",
       " 'trata.',\n",
       " 'tratar',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'un',\n",
       " 'una',\n",
       " 'unica',\n",
       " 'usar',\n",
       " 'utiliza',\n",
       " 'va',\n",
       " 'veces',\n",
       " 'veo',\n",
       " 'ver',\n",
       " 'verguenza.',\n",
       " 'verticalidad,',\n",
       " 'vez',\n",
       " 'visible',\n",
       " 'vives',\n",
       " 'voz',\n",
       " 'y',\n",
       " 'y,',\n",
       " 'yo',\n",
       " '¿y',\n",
       " '‘mundanalidad’'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encuentra todas las palabras únicas en nuestro corpus\n",
    "vocabulary = set(w for s in train_sentences for w in s)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "39oh3ZCwQskW"
   },
   "outputs": [],
   "source": [
    "# Agrega el token desconocido a nuestro vocabulario\n",
    "vocabulary.add(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NNnjvOJOQskW",
    "outputId": "c49b0d02-021f-4b84-8a51-a10214ce3721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<pad>',\n",
       " 'el',\n",
       " 'arte',\n",
       " 'es',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'dejas',\n",
       " 'salir',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregua el token <pad> a nuestro vocabulario para tener sentencias validas en nuestro alrededor\n",
    "vocabulary.add(\"<pad>\")\n",
    "\n",
    "# Función que rellena la oración dada\n",
    "# Estamos introduciendo esta función aquí como un ejemplo\n",
    "# Lo utilizaremos más adelante en el tutorial.\n",
    "def pad_window(sentence, window_size, pad_token=\"<pad>\"):\n",
    "  window = [pad_token] * window_size\n",
    "  return window + sentence + window\n",
    "\n",
    "# Muestra un ejemplo de relleno\n",
    "window_size = 2\n",
    "pad_window(train_sentences[0], window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "dZ4l1hglQskX",
    "outputId": "f0a11ec7-ac22-4339-d78b-4c46c0281e3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(la': 0,\n",
       " '(que': 1,\n",
       " '<pad>': 2,\n",
       " '<unk>': 3,\n",
       " '[artistica].': 4,\n",
       " 'a': 5,\n",
       " 'absolutamente': 6,\n",
       " 'accion.': 7,\n",
       " 'acepto': 8,\n",
       " 'actual': 9,\n",
       " 'alborotador.': 10,\n",
       " 'alcanzaras.': 11,\n",
       " 'algo': 12,\n",
       " 'algo,': 13,\n",
       " 'alguien': 14,\n",
       " 'alguna.': 15,\n",
       " 'alma)': 16,\n",
       " 'alrededor': 17,\n",
       " 'amenaza.': 18,\n",
       " 'anteriormente,': 19,\n",
       " 'apariencia': 20,\n",
       " 'aprende': 21,\n",
       " 'aquello': 22,\n",
       " 'arquitectura': 23,\n",
       " 'arte': 24,\n",
       " 'arte,': 25,\n",
       " 'arte.': 26,\n",
       " 'artes': 27,\n",
       " 'artista': 28,\n",
       " 'artista.': 29,\n",
       " 'artistica': 30,\n",
       " 'artisticas.': 31,\n",
       " 'atrae': 32,\n",
       " 'autobiografico.': 33,\n",
       " 'bella': 34,\n",
       " 'bella,': 35,\n",
       " 'bellas': 36,\n",
       " 'belleza': 37,\n",
       " 'bonita': 38,\n",
       " 'buen': 39,\n",
       " 'cada': 40,\n",
       " 'cambia': 41,\n",
       " 'cambio': 42,\n",
       " 'carcel': 43,\n",
       " 'circularidad': 44,\n",
       " 'color': 45,\n",
       " 'combina': 46,\n",
       " 'combinacion': 47,\n",
       " 'comenzar': 48,\n",
       " 'como': 49,\n",
       " 'como)': 50,\n",
       " 'comprender': 51,\n",
       " 'comprender:': 52,\n",
       " 'comprendida,': 53,\n",
       " 'comunicarse': 54,\n",
       " 'con': 55,\n",
       " 'congelada.': 56,\n",
       " 'consiste': 57,\n",
       " 'constante.': 58,\n",
       " 'constantemente': 59,\n",
       " 'construir': 60,\n",
       " 'cordura.': 61,\n",
       " 'corruptora': 62,\n",
       " 'cosa': 63,\n",
       " 'cosa.': 64,\n",
       " 'cosas': 65,\n",
       " 'cosas,': 66,\n",
       " 'costumbre': 67,\n",
       " 'crea.': 68,\n",
       " 'creatividad': 69,\n",
       " 'cuando': 70,\n",
       " 'cuerno.': 71,\n",
       " 'de': 72,\n",
       " 'deber': 73,\n",
       " 'decir': 74,\n",
       " 'decorativo': 75,\n",
       " 'decorativo.': 76,\n",
       " 'dejada': 77,\n",
       " 'dejas': 78,\n",
       " 'del': 79,\n",
       " 'demas,': 80,\n",
       " 'deriva': 81,\n",
       " 'descifrar': 82,\n",
       " 'deseo': 83,\n",
       " 'desesperado': 84,\n",
       " 'dias.': 85,\n",
       " 'dicen': 86,\n",
       " 'diversion,': 87,\n",
       " 'donde': 88,\n",
       " 'echar': 89,\n",
       " 'el': 90,\n",
       " 'ellas.': 91,\n",
       " 'emociones': 92,\n",
       " 'empeño': 93,\n",
       " 'en': 94,\n",
       " 'engañosa,': 95,\n",
       " 'ensanchamiento': 96,\n",
       " 'entiendo': 97,\n",
       " 'entre': 98,\n",
       " 'es': 99,\n",
       " 'es,': 100,\n",
       " 'es.': 101,\n",
       " 'escena': 102,\n",
       " 'eso': 103,\n",
       " 'espacio': 104,\n",
       " 'espectador,': 105,\n",
       " 'esta': 106,\n",
       " 'estan': 107,\n",
       " 'estas': 108,\n",
       " 'esto': 109,\n",
       " 'estoy': 110,\n",
       " 'estuve': 111,\n",
       " 'existencia.': 112,\n",
       " 'experiencia,': 113,\n",
       " 'expresar': 114,\n",
       " 'expresar,': 115,\n",
       " 'exprimir': 116,\n",
       " 'externa': 117,\n",
       " 'forma': 118,\n",
       " 'forma,': 119,\n",
       " 'fronteras': 120,\n",
       " 'furor': 121,\n",
       " 'garantia': 122,\n",
       " 'generado': 123,\n",
       " 'grandes': 124,\n",
       " 'grosera': 125,\n",
       " 'hablar': 126,\n",
       " 'hace': 127,\n",
       " 'hacer': 128,\n",
       " 'hacia': 129,\n",
       " 'haciendo': 130,\n",
       " 'han': 131,\n",
       " 'hay': 132,\n",
       " 'hemos': 133,\n",
       " 'hombres.': 134,\n",
       " 'horizontalidad': 135,\n",
       " 'horizontes': 136,\n",
       " 'huella': 137,\n",
       " 'humildemente,': 138,\n",
       " 'imagen': 139,\n",
       " 'imaginaba.': 140,\n",
       " 'indiscrecion.': 141,\n",
       " 'infamia,': 142,\n",
       " 'inmediatez.': 143,\n",
       " 'inspiracion': 144,\n",
       " 'inspiracion.': 145,\n",
       " 'intensas,': 146,\n",
       " 'interior.': 147,\n",
       " 'inutil': 148,\n",
       " 'involucrado': 149,\n",
       " 'la': 150,\n",
       " 'las': 151,\n",
       " 'lentamente,': 152,\n",
       " 'libertad.': 153,\n",
       " 'ligado': 154,\n",
       " 'limitadora': 155,\n",
       " 'linea': 156,\n",
       " 'literatura': 157,\n",
       " 'llegado': 158,\n",
       " 'llena': 159,\n",
       " 'lo': 160,\n",
       " 'los': 161,\n",
       " 'mas': 162,\n",
       " 'me': 163,\n",
       " 'mediocridad.': 164,\n",
       " 'meditacion': 165,\n",
       " 'menos': 166,\n",
       " 'mero': 167,\n",
       " 'mi': 168,\n",
       " 'mi,': 169,\n",
       " 'miedo': 170,\n",
       " 'misma': 171,\n",
       " 'montañas.': 172,\n",
       " 'muerte,': 173,\n",
       " 'mueve': 174,\n",
       " 'musica': 175,\n",
       " 'musica.': 176,\n",
       " 'muy': 177,\n",
       " 'nada': 178,\n",
       " 'nada,': 179,\n",
       " 'naturaleza': 180,\n",
       " 'no': 181,\n",
       " 'nocivo': 182,\n",
       " 'nos': 183,\n",
       " 'nosotros': 184,\n",
       " 'nuestro': 185,\n",
       " 'nuevo,': 186,\n",
       " 'nunca': 187,\n",
       " 'o': 188,\n",
       " 'objetivo': 189,\n",
       " 'obligacion': 190,\n",
       " 'observacion': 191,\n",
       " 'otro.': 192,\n",
       " 'pacto': 193,\n",
       " 'papel': 194,\n",
       " 'para': 195,\n",
       " 'parece': 196,\n",
       " 'participa': 197,\n",
       " 'patadas': 198,\n",
       " 'pendulo;': 199,\n",
       " 'pensamientos,': 200,\n",
       " 'peor': 201,\n",
       " 'perder': 202,\n",
       " 'perdida': 203,\n",
       " 'perfeccion,': 204,\n",
       " 'performance': 205,\n",
       " 'pero': 206,\n",
       " 'perseguir': 207,\n",
       " 'persona': 208,\n",
       " 'personas,': 209,\n",
       " 'pesadillas.': 210,\n",
       " 'pienso': 211,\n",
       " 'pinto': 212,\n",
       " 'poco': 213,\n",
       " 'poder': 214,\n",
       " 'por': 215,\n",
       " 'posible': 216,\n",
       " 'preguntas,': 217,\n",
       " 'preocupado': 218,\n",
       " 'presencia': 219,\n",
       " 'problema.': 220,\n",
       " 'produce,': 221,\n",
       " 'profesional,': 222,\n",
       " 'propia': 223,\n",
       " 'propios': 224,\n",
       " 'publico': 225,\n",
       " 'puedas': 226,\n",
       " 'puertas': 227,\n",
       " 'que': 228,\n",
       " 'que,': 229,\n",
       " 'que?': 230,\n",
       " 'queria': 231,\n",
       " 'realidad.': 232,\n",
       " 'realmente': 233,\n",
       " 'reglas': 234,\n",
       " 'regresar': 235,\n",
       " 'representacion': 236,\n",
       " 'representar': 237,\n",
       " 'representativas': 238,\n",
       " 'reproduce': 239,\n",
       " 'resiste': 240,\n",
       " 'resiste:': 241,\n",
       " 'responderlas.': 242,\n",
       " 'responsabilidad': 243,\n",
       " 'revela': 244,\n",
       " 'revolucion,': 245,\n",
       " 'riguroso,': 246,\n",
       " 'romperlas': 247,\n",
       " 'sabiduria.': 248,\n",
       " 'salir': 249,\n",
       " 'se': 250,\n",
       " 'sea': 251,\n",
       " 'secretos.': 252,\n",
       " 'ser': 253,\n",
       " 'servicio': 254,\n",
       " 'servidumbre,': 255,\n",
       " 'si': 256,\n",
       " 'siempre': 257,\n",
       " 'siento': 258,\n",
       " 'significado': 259,\n",
       " 'sigue': 260,\n",
       " 'silencio': 261,\n",
       " 'sin': 262,\n",
       " 'sino': 263,\n",
       " 'sobre': 264,\n",
       " 'social': 265,\n",
       " 'sociedad': 266,\n",
       " 'solamente': 267,\n",
       " 'son': 268,\n",
       " 'sonido': 269,\n",
       " 'soñar.': 270,\n",
       " 'su': 271,\n",
       " 'sueños': 272,\n",
       " 'sufrimientos': 273,\n",
       " 'superficial,': 274,\n",
       " 'supongo': 275,\n",
       " 'tambien': 276,\n",
       " 'tan': 277,\n",
       " 'te': 278,\n",
       " 'tengas': 279,\n",
       " 'tengo': 280,\n",
       " 'teorias': 281,\n",
       " 'terminan': 282,\n",
       " 'ti.': 283,\n",
       " 'tiempo': 284,\n",
       " 'tiempo,': 285,\n",
       " 'tiene': 286,\n",
       " 'tierra': 287,\n",
       " 'tipo': 288,\n",
       " 'toda': 289,\n",
       " 'todas': 290,\n",
       " 'todavia': 291,\n",
       " 'todo': 292,\n",
       " 'todos': 293,\n",
       " 'trabajar': 294,\n",
       " 'trabajo': 295,\n",
       " 'transformacion.': 296,\n",
       " 'transitoria,': 297,\n",
       " 'trata.': 298,\n",
       " 'tratar': 299,\n",
       " 'tu': 300,\n",
       " 'tus': 301,\n",
       " 'un': 302,\n",
       " 'una': 303,\n",
       " 'unica': 304,\n",
       " 'usar': 305,\n",
       " 'utiliza': 306,\n",
       " 'va': 307,\n",
       " 'veces': 308,\n",
       " 'veo': 309,\n",
       " 'ver': 310,\n",
       " 'verguenza.': 311,\n",
       " 'verticalidad,': 312,\n",
       " 'vez': 313,\n",
       " 'visible': 314,\n",
       " 'vives': 315,\n",
       " 'voz': 316,\n",
       " 'y': 317,\n",
       " 'y,': 318,\n",
       " 'yo': 319,\n",
       " '¿y': 320,\n",
       " '‘mundanalidad’': 321}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word = sorted(list(vocabulary))\n",
    "\n",
    "# Creando un diccionario para encontrar el índice de una palabra dada\n",
    "word_to_ix = {word: ind for ind, word in enumerate(ix_to_word)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga9gUSuzQskX"
   },
   "source": [
    "### Token a indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "qSjgFSGUQskX"
   },
   "outputs": [],
   "source": [
    "### Función para convertir tokens en indices\n",
    "\n",
    "def convert_tokens_to_indices(sentence, word_to_ix):\n",
    "  return [word_to_ix.get(token, word_to_ix[\"<unk>\"]) for token in sentence]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weZfus27QskX"
   },
   "source": [
    "### Reemplazo de palabras a indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "mh3Pt1UaQskX",
    "outputId": "f9464e2a-b5e2-4186-d9b3-c8b962d97009"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90, 24, 99, 160, 228, 78, 249],\n",
       " [90,\n",
       "  24,\n",
       "  181,\n",
       "  239,\n",
       "  22,\n",
       "  228,\n",
       "  99,\n",
       "  314,\n",
       "  263,\n",
       "  228,\n",
       "  127,\n",
       "  314,\n",
       "  22,\n",
       "  228,\n",
       "  181,\n",
       "  257,\n",
       "  160,\n",
       "  101],\n",
       " [90, 24, 286, 150, 38, 67, 72, 89, 5, 202, 290, 151, 281, 31],\n",
       " [90, 24, 99, 303, 122, 72, 61],\n",
       " [21, 151, 234, 49, 302, 222, 195, 228, 226, 247, 49, 302, 29],\n",
       " [187, 212, 272, 188, 210, 212, 168, 223, 232],\n",
       " [181, 279, 170, 72, 150, 204, 187, 150, 11],\n",
       " [90, 24, 81, 72, 302, 83, 72, 150, 208, 195, 54, 55, 192],\n",
       " [90, 194, 72, 151, 27, 238],\n",
       " [231,\n",
       "  48,\n",
       "  303,\n",
       "  245,\n",
       "  305,\n",
       "  90,\n",
       "  24,\n",
       "  195,\n",
       "  60,\n",
       "  90,\n",
       "  288,\n",
       "  72,\n",
       "  266,\n",
       "  228,\n",
       "  319,\n",
       "  171,\n",
       "  140],\n",
       " [309, 90, 24, 317, 150, 157, 49, 302, 216, 96, 72, 136, 129, 150, 153],\n",
       " [97,\n",
       "  228,\n",
       "  302,\n",
       "  28,\n",
       "  99,\n",
       "  14,\n",
       "  229,\n",
       "  98,\n",
       "  90,\n",
       "  261,\n",
       "  72,\n",
       "  161,\n",
       "  80,\n",
       "  306,\n",
       "  271,\n",
       "  316,\n",
       "  195,\n",
       "  74,\n",
       "  13,\n",
       "  317,\n",
       "  228,\n",
       "  286,\n",
       "  150,\n",
       "  190,\n",
       "  228,\n",
       "  109,\n",
       "  181,\n",
       "  251,\n",
       "  12,\n",
       "  148,\n",
       "  263,\n",
       "  12,\n",
       "  228,\n",
       "  72,\n",
       "  302,\n",
       "  254,\n",
       "  5,\n",
       "  161,\n",
       "  134],\n",
       " [90, 24, 106, 154, 5, 160, 228, 291, 181, 250, 68],\n",
       " [132,\n",
       "  5,\n",
       "  185,\n",
       "  17,\n",
       "  92,\n",
       "  177,\n",
       "  36,\n",
       "  317,\n",
       "  94,\n",
       "  90,\n",
       "  25,\n",
       "  88,\n",
       "  107,\n",
       "  151,\n",
       "  162,\n",
       "  146,\n",
       "  181,\n",
       "  8,\n",
       "  150,\n",
       "  164,\n",
       "  132,\n",
       "  25,\n",
       "  181,\n",
       "  24,\n",
       "  76,\n",
       "  90,\n",
       "  24,\n",
       "  99,\n",
       "  12,\n",
       "  246,\n",
       "  90,\n",
       "  24,\n",
       "  75,\n",
       "  181,\n",
       "  160,\n",
       "  100,\n",
       "  99,\n",
       "  274,\n",
       "  10],\n",
       " [5,\n",
       "  308,\n",
       "  211,\n",
       "  228,\n",
       "  160,\n",
       "  201,\n",
       "  99,\n",
       "  150,\n",
       "  9,\n",
       "  321,\n",
       "  72,\n",
       "  289,\n",
       "  150,\n",
       "  102,\n",
       "  4,\n",
       "  99,\n",
       "  150,\n",
       "  63,\n",
       "  162,\n",
       "  95,\n",
       "  62,\n",
       "  317,\n",
       "  297,\n",
       "  159,\n",
       "  72,\n",
       "  198,\n",
       "  317,\n",
       "  87,\n",
       "  206,\n",
       "  277,\n",
       "  213,\n",
       "  228,\n",
       "  310,\n",
       "  55,\n",
       "  160,\n",
       "  228,\n",
       "  233,\n",
       "  250,\n",
       "  298,\n",
       "  286,\n",
       "  228,\n",
       "  310,\n",
       "  55,\n",
       "  185,\n",
       "  285,\n",
       "  302,\n",
       "  193,\n",
       "  84,\n",
       "  264,\n",
       "  90,\n",
       "  214,\n",
       "  72,\n",
       "  150,\n",
       "  143,\n",
       "  206,\n",
       "  163,\n",
       "  258,\n",
       "  40,\n",
       "  313,\n",
       "  166,\n",
       "  218,\n",
       "  215,\n",
       "  109,\n",
       "  49,\n",
       "  302,\n",
       "  220,\n",
       "  320,\n",
       "  230,\n",
       "  181,\n",
       "  132,\n",
       "  18],\n",
       " [292,\n",
       "  168,\n",
       "  295,\n",
       "  260,\n",
       "  49,\n",
       "  302,\n",
       "  199,\n",
       "  196,\n",
       "  235,\n",
       "  5,\n",
       "  12,\n",
       "  94,\n",
       "  160,\n",
       "  228,\n",
       "  111,\n",
       "  149,\n",
       "  19,\n",
       "  188,\n",
       "  250,\n",
       "  174,\n",
       "  98,\n",
       "  150,\n",
       "  135,\n",
       "  317,\n",
       "  150,\n",
       "  312,\n",
       "  150,\n",
       "  44,\n",
       "  188,\n",
       "  303,\n",
       "  47,\n",
       "  72,\n",
       "  91,\n",
       "  195,\n",
       "  169,\n",
       "  275,\n",
       "  228,\n",
       "  90,\n",
       "  42,\n",
       "  99,\n",
       "  150,\n",
       "  304,\n",
       "  58],\n",
       " [99,\n",
       "  168,\n",
       "  73,\n",
       "  114,\n",
       "  161,\n",
       "  273,\n",
       "  72,\n",
       "  151,\n",
       "  209,\n",
       "  161,\n",
       "  273,\n",
       "  228,\n",
       "  187,\n",
       "  282,\n",
       "  317,\n",
       "  228,\n",
       "  268,\n",
       "  277,\n",
       "  124,\n",
       "  49,\n",
       "  151,\n",
       "  172],\n",
       " [0,\n",
       "  205,\n",
       "  99,\n",
       "  50,\n",
       "  90,\n",
       "  24,\n",
       "  228,\n",
       "  46,\n",
       "  90,\n",
       "  284,\n",
       "  317,\n",
       "  90,\n",
       "  104,\n",
       "  55,\n",
       "  150,\n",
       "  219,\n",
       "  72,\n",
       "  302,\n",
       "  225,\n",
       "  228,\n",
       "  181,\n",
       "  99,\n",
       "  302,\n",
       "  167,\n",
       "  105,\n",
       "  263,\n",
       "  228,\n",
       "  276,\n",
       "  197,\n",
       "  72,\n",
       "  150,\n",
       "  7],\n",
       " [181, 132, 24, 262, 296],\n",
       " [90, 24, 183, 32, 267, 70, 244, 94, 184, 252],\n",
       " [292, 24, 99, 33],\n",
       " [90, 24, 181, 41, 179, 90, 24, 278, 41, 5, 283],\n",
       " [70, 110, 130, 25, 181, 280, 6, 243, 265, 15, 99, 49, 270],\n",
       " [150,\n",
       "  175,\n",
       "  99,\n",
       "  300,\n",
       "  223,\n",
       "  113,\n",
       "  301,\n",
       "  224,\n",
       "  200,\n",
       "  300,\n",
       "  248,\n",
       "  256,\n",
       "  181,\n",
       "  150,\n",
       "  315,\n",
       "  181,\n",
       "  307,\n",
       "  5,\n",
       "  249,\n",
       "  72,\n",
       "  300,\n",
       "  71,\n",
       "  278,\n",
       "  86,\n",
       "  228,\n",
       "  132,\n",
       "  303,\n",
       "  156,\n",
       "  155,\n",
       "  195,\n",
       "  150,\n",
       "  176,\n",
       "  206,\n",
       "  181,\n",
       "  132,\n",
       "  120,\n",
       "  195,\n",
       "  90,\n",
       "  26],\n",
       " [292, 39, 24, 99, 303, 141],\n",
       " [150, 144, 99, 294, 293, 161, 85],\n",
       " [90,\n",
       "  24,\n",
       "  99,\n",
       "  160,\n",
       "  228,\n",
       "  241,\n",
       "  240,\n",
       "  5,\n",
       "  150,\n",
       "  173,\n",
       "  5,\n",
       "  150,\n",
       "  255,\n",
       "  5,\n",
       "  150,\n",
       "  142,\n",
       "  5,\n",
       "  150,\n",
       "  311],\n",
       " [178, 99, 162, 182, 195, 150, 69, 228, 90, 121, 72, 150, 145],\n",
       " [90, 194, 79, 28, 99, 128, 217, 181, 242],\n",
       " [150, 23, 99, 175, 56],\n",
       " [90,\n",
       "  126,\n",
       "  72,\n",
       "  108,\n",
       "  65,\n",
       "  317,\n",
       "  90,\n",
       "  299,\n",
       "  72,\n",
       "  51,\n",
       "  271,\n",
       "  180,\n",
       "  318,\n",
       "  303,\n",
       "  313,\n",
       "  53,\n",
       "  90,\n",
       "  299,\n",
       "  152,\n",
       "  138,\n",
       "  59,\n",
       "  72,\n",
       "  115,\n",
       "  72,\n",
       "  116,\n",
       "  72,\n",
       "  186,\n",
       "  72,\n",
       "  150,\n",
       "  287,\n",
       "  125,\n",
       "  188,\n",
       "  72,\n",
       "  160,\n",
       "  228,\n",
       "  150,\n",
       "  287,\n",
       "  221,\n",
       "  72,\n",
       "  150,\n",
       "  119,\n",
       "  79,\n",
       "  269,\n",
       "  317,\n",
       "  79,\n",
       "  45,\n",
       "  1,\n",
       "  268,\n",
       "  151,\n",
       "  227,\n",
       "  72,\n",
       "  150,\n",
       "  43,\n",
       "  79,\n",
       "  16,\n",
       "  303,\n",
       "  139,\n",
       "  72,\n",
       "  150,\n",
       "  37,\n",
       "  228,\n",
       "  133,\n",
       "  158,\n",
       "  5,\n",
       "  52,\n",
       "  103,\n",
       "  99,\n",
       "  90,\n",
       "  26],\n",
       " [90,\n",
       "  24,\n",
       "  196,\n",
       "  253,\n",
       "  90,\n",
       "  93,\n",
       "  215,\n",
       "  82,\n",
       "  188,\n",
       "  207,\n",
       "  150,\n",
       "  137,\n",
       "  77,\n",
       "  215,\n",
       "  303,\n",
       "  118,\n",
       "  203,\n",
       "  72,\n",
       "  112],\n",
       " [150,\n",
       "  37,\n",
       "  30,\n",
       "  181,\n",
       "  57,\n",
       "  94,\n",
       "  237,\n",
       "  303,\n",
       "  63,\n",
       "  35,\n",
       "  263,\n",
       "  94,\n",
       "  150,\n",
       "  34,\n",
       "  236,\n",
       "  72,\n",
       "  303,\n",
       "  64],\n",
       " [90,\n",
       "  189,\n",
       "  79,\n",
       "  24,\n",
       "  181,\n",
       "  99,\n",
       "  237,\n",
       "  150,\n",
       "  20,\n",
       "  117,\n",
       "  72,\n",
       "  151,\n",
       "  66,\n",
       "  263,\n",
       "  271,\n",
       "  259,\n",
       "  147],\n",
       " [150, 191, 72, 150, 180, 317, 150, 165, 131, 123, 90, 26]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convirtiendo nuestras sentencias a indices\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "example_padded_indices = [convert_token_to_indices(s, word_to_ix) for s in train_sentences]\n",
    "\n",
    "example_padded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "3r25cs3oQskX",
    "outputId": "dbb48bd8-7569-4bc9-89f9-b15959ad7213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.5256, -0.7502, -0.6540, -1.6095],\n",
       "         [-0.1002, -0.6092, -0.9798, -1.6091],\n",
       "         [-0.7121,  0.3037, -0.7773, -0.2515],\n",
       "         ...,\n",
       "         [-1.6363, -1.0782, -0.6049, -0.8409],\n",
       "         [ 0.2039, -0.4010, -0.5088,  1.3090],\n",
       "         [ 1.0709,  0.2065, -1.0187, -2.0848]], requires_grad=True)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Representamos en vectores de 4 dimensiones\n",
    "# Elegimos 4 debido a que solamente elegimos 4 categorias al inicio.\n",
    "# fijo semilla\n",
    "torch.manual_seed(1)\n",
    "embedding_dim = 4\n",
    "embeds = nn.Embedding(len(vocabulary), embedding_dim)\n",
    "\n",
    "# Imprimiendo los parámetros en nuestra tabla de embedding\n",
    "list(embeds.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5s49eGEcQskY"
   },
   "source": [
    "### Definición del dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "gdPzSyHRQskY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "def custom_collate_fn(batch, window_size, word_to_ix):\n",
    "  # preparando los puntos de datos\n",
    "  x, y = zip(*batch)  # Zip maneja dos dimenciones en simultaneo.\n",
    "  x = [pad_window(s, window_size=window_size) for s in x]\n",
    "  x = [convert_tokens_to_indices(s, word_to_ix) for s in x]\n",
    "\n",
    "  # rellena x tal que todas las muestras en el batch tengan el mismo tamano\n",
    "  pad_token_ix = word_to_ix[\"<pad>\"]\n",
    "  x = [torch.LongTensor(x_i) for x_i in x]\n",
    "  x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=pad_token_ix)\n",
    "\n",
    "  # Rellena \"y\" y guarda la longitud\n",
    "  lengths = [len(label) for label in y]\n",
    "  lenghts = torch.LongTensor(lengths)\n",
    "  y = [torch.LongTensor(y_i) for y_i in y]\n",
    "  y_padded = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=0)\n",
    "\n",
    "  return x_padded, y_padded, lenghts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "tyuTB_uBQskY",
    "outputId": "26163632-2b6a-46b4-fb71-08cf79d225c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90,  24, 181, 239,  22, 228,  99, 314, 263, 228, 127, 314,\n",
      "          22, 228, 181, 257, 160, 101,   2,   2,   2],\n",
      "        [  2,   2,  90,  24, 196, 253,  90,  93, 215,  82, 188, 207, 150, 137,\n",
      "          77, 215, 303, 118, 203,  72, 112,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([18, 19])\n",
      "\n",
      "Iteration 1\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 132,   5, 185,  17,  92, 177,  36, 317,  94,  90,  25,  88,\n",
      "         107, 151, 162, 146, 181,   8, 150, 164, 132,  25, 181,  24,  76,  90,\n",
      "          24,  99,  12, 246,  90,  24,  75, 181, 160, 100,  99, 274,  10,   2,\n",
      "           2],\n",
      "        [  2,   2,  90,  24, 286, 150,  38,  67,  72,  89,   5, 202, 290, 151,\n",
      "         281,  31,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "         0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([39, 14])\n",
      "\n",
      "Iteration 2\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90, 194,  79,  28,  99, 128, 217, 181, 242,   2,   2],\n",
      "        [  2,   2, 292,  24,  99,  33,   2,   2,   2,   2,   2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([9, 4])\n",
      "\n",
      "Iteration 3\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 150,  23,  99, 175,  56,   2,   2,   2,   2],\n",
      "        [  2,   2,  90,  24,  99, 303, 122,  72,  61,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([5, 7])\n",
      "\n",
      "Iteration 4\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 150, 144,  99, 294, 293, 161,  85,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2],\n",
      "        [  2,   2,  97, 228, 302,  28,  99,  14, 229,  98,  90, 261,  72, 161,\n",
      "          80, 306, 271, 316, 195,  74,  13, 317, 228, 286, 150, 190, 228, 109,\n",
      "         181, 251,  12, 148, 263,  12, 228,  72, 302, 254,   5, 161, 134,   2,\n",
      "           2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([ 7, 39])\n",
      "\n",
      "Iteration 5\n",
      "Batched Input:\n",
      "tensor([[  2,   2,   5, 308, 211, 228, 160, 201,  99, 150,   9, 321,  72, 289,\n",
      "         150, 102,   4,  99, 150,  63, 162,  95,  62, 317, 297, 159,  72, 198,\n",
      "         317,  87, 206, 277, 213, 228, 310,  55, 160, 228, 233, 250, 298, 286,\n",
      "         228, 310,  55, 185, 285, 302, 193,  84, 264,  90, 214,  72, 150, 143,\n",
      "         206, 163, 258,  40, 313, 166, 218, 215, 109,  49, 302, 220, 320, 230,\n",
      "         181, 132,  18,   2,   2],\n",
      "        [  2,   2,   0, 205,  99,  50,  90,  24, 228,  46,  90, 284, 317,  90,\n",
      "         104,  55, 150, 219,  72, 302, 225, 228, 181,  99, 302, 167, 105, 263,\n",
      "         228, 276, 197,  72, 150,   7,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([71, 32])\n",
      "\n",
      "Iteration 6\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 309,  90,  24, 317, 150, 157,  49, 302, 216,  96,  72, 136,\n",
      "         129, 150, 153,   2,   2],\n",
      "        [  2,   2,  21, 151, 234,  49, 302, 222, 195, 228, 226, 247,  49, 302,\n",
      "          29,   2,   2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([15, 13])\n",
      "\n",
      "Iteration 7\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90, 194,  72, 151,  27, 238,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2, 150,  37,  30, 181,  57,  94, 237, 303,  63,  35, 263,  94,\n",
      "         150,  34, 236,  72, 303,  64,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([ 6, 18])\n",
      "\n",
      "Iteration 8\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 292, 168, 295, 260,  49, 302, 199, 196, 235,   5,  12,  94,\n",
      "         160, 228, 111, 149,  19, 188, 250, 174,  98, 150, 135, 317, 150, 312,\n",
      "         150,  44, 188, 303,  47,  72,  91, 195, 169, 275, 228,  90,  42,  99,\n",
      "         150, 304,  58,   2,   2],\n",
      "        [  2,   2,  99, 168,  73, 114, 161, 273,  72, 151, 209, 161, 273, 228,\n",
      "         187, 282, 317, 228, 268, 277, 124,  49, 151, 172,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([43, 22])\n",
      "\n",
      "Iteration 9\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90, 126,  72, 108,  65, 317,  90, 299,  72,  51, 271, 180,\n",
      "         318, 303, 313,  53,  90, 299, 152, 138,  59,  72, 115,  72, 116,  72,\n",
      "         186,  72, 150, 287, 125, 188,  72, 160, 228, 150, 287, 221,  72, 150,\n",
      "         119,  79, 269, 317,  79,  45,   1, 268, 151, 227,  72, 150,  43,  79,\n",
      "          16, 303, 139,  72, 150,  37, 228, 133, 158,   5,  52, 103,  99,  90,\n",
      "          26,   2,   2],\n",
      "        [  2,   2,  90,  24, 183,  32, 267,  70, 244,  94, 184, 252,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([69, 10])\n",
      "\n",
      "Iteration 10\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 178,  99, 162, 182, 195, 150,  69, 228,  90, 121,  72, 150,\n",
      "         145,   2,   2],\n",
      "        [  2,   2, 150, 191,  72, 150, 180, 317, 150, 165, 131, 123,  90,  26,\n",
      "           2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([13, 12])\n",
      "\n",
      "Iteration 11\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90,  24,  99, 160, 228,  78, 249,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2,  90,  24,  99, 160, 228, 241, 240,   5, 150, 173,   5, 150,\n",
      "         255,   5, 150, 142,   5, 150, 311,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([ 7, 19])\n",
      "\n",
      "Iteration 12\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90, 189,  79,  24, 181,  99, 237, 150,  20, 117,  72, 151,\n",
      "          66, 263, 271, 259, 147,   2,   2],\n",
      "        [  2,   2,  90,  24,  81,  72, 302,  83,  72, 150, 208, 195,  54,  55,\n",
      "         192,   2,   2,   2,   2,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([17, 13])\n",
      "\n",
      "Iteration 13\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 150, 175,  99, 300, 223, 113, 301, 224, 200, 300, 248, 256,\n",
      "         181, 150, 315, 181, 307,   5, 249,  72, 300,  71, 278,  86, 228, 132,\n",
      "         303, 156, 155, 195, 150, 176, 206, 181, 132, 120, 195,  90,  26,   2,\n",
      "           2],\n",
      "        [  2,   2,  90,  24, 106, 154,   5, 160, 228, 291, 181, 250,  68,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([39, 11])\n",
      "\n",
      "Iteration 14\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 292,  39,  24,  99, 303, 141,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2, 231,  48, 303, 245, 305,  90,  24, 195,  60,  90, 288,  72,\n",
      "         266, 228, 319, 171, 140,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([ 6, 17])\n",
      "\n",
      "Iteration 15\n",
      "Batched Input:\n",
      "tensor([[  2,   2, 181, 132,  24, 262, 296,   2,   2,   2,   2,   2,   2],\n",
      "        [  2,   2, 181, 279, 170,  72, 150, 204, 187, 150,  11,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([5, 9])\n",
      "\n",
      "Iteration 16\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  90,  24, 181,  41, 179,  90,  24, 278,  41,   5, 283,   2,\n",
      "           2],\n",
      "        [  2,   2, 187, 212, 272, 188, 210, 212, 168, 223, 232,   2,   2,   2,\n",
      "           2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([11,  9])\n",
      "\n",
      "Iteration 17\n",
      "Batched Input:\n",
      "tensor([[  2,   2,  70, 110, 130,  25, 181, 280,   6, 243, 265,  15,  99,  49,\n",
      "         270,   2,   2]])\n",
      "Batched Labels:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Batched Lengths:\n",
      "tensor([13])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## inicializando DATALOADER\n",
    "#Parámetros a pasar al DataLoader\n",
    "from functools import partial\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instancia el DataLoader\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Va a traves de un ciclo\n",
    "counter = 0\n",
    "for batched_x, batched_y, batched_lengths in loader:\n",
    "  print(f\"Iteration {counter}\")\n",
    "  print(\"Batched Input:\")\n",
    "  print(batched_x)\n",
    "  print(\"Batched Labels:\")\n",
    "  print(batched_y)\n",
    "  print(\"Batched Lengths:\")\n",
    "  print(batched_lengths)\n",
    "  print(\"\")\n",
    "  counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "8PHrT11AQskY",
    "outputId": "7db4a54e-e7df-4513-80c7-960b1bb0fc53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: \n",
      "tensor([[  2,   2,  70, 110, 130,  25, 181, 280,   6, 243, 265,  15,  99,  49,\n",
      "         270,   2,   2]])\n",
      "\n",
      "Windows: \n",
      "tensor([[[  2,   2,  70, 110, 130],\n",
      "         [  2,  70, 110, 130,  25],\n",
      "         [ 70, 110, 130,  25, 181],\n",
      "         [110, 130,  25, 181, 280],\n",
      "         [130,  25, 181, 280,   6],\n",
      "         [ 25, 181, 280,   6, 243],\n",
      "         [181, 280,   6, 243, 265],\n",
      "         [280,   6, 243, 265,  15],\n",
      "         [  6, 243, 265,  15,  99],\n",
      "         [243, 265,  15,  99,  49],\n",
      "         [265,  15,  99,  49, 270],\n",
      "         [ 15,  99,  49, 270,   2],\n",
      "         [ 99,  49, 270,   2,   2]]])\n"
     ]
    }
   ],
   "source": [
    "### Representación del tensor original en segmentos de ventanas \n",
    "# muestra el tensor original\n",
    "print(f\"Original Tensor: \")\n",
    "print(batched_x)\n",
    "print(\"\")\n",
    "\n",
    "# Crea los 2 * 2 + 1 chunkstrozos\n",
    "chunk = batched_x.unfold(1, window_size*2 + 1, 1)\n",
    "print(f\"Windows: \")\n",
    "print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lkALUmwQskZ"
   },
   "source": [
    "### Modelo de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "SmyK8dZyQskZ"
   },
   "outputs": [],
   "source": [
    "class WordWindowClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, hyperparameters, vocab_size, pad_ix=0):\n",
    "    super(WordWindowClassifier, self).__init__()\n",
    "    \n",
    "    \"\"\" Instancia las variabless \"\"\"\n",
    "    self.window_size = hyperparameters[\"window_size\"]\n",
    "    self.embed_dim = hyperparameters[\"embed_dim\"]\n",
    "    self.hidden_dim = hyperparameters[\"hidden_dim\"]\n",
    "    self.freeze_embeddings = hyperparameters[\"freeze_embeddings\"]\n",
    "\n",
    "    \"\"\" Capa de Embedding      \n",
    "    Toma un tensor que contiene los índices de los embeddings y devuelve los embeddings\n",
    "    correspondientes. La salida es de dimensión (número_de_índices * dimension_embedding).\n",
    "\n",
    "     Si freeze_embeddings es True, configura los parámetros de la capa de embedding para que sean\n",
    "     no entrenables. Esto es útil si solo queremos cambiar los parámetros que no sean de los embeddings.\n",
    "\n",
    "    \"\"\"\n",
    "    self.embeds = nn.Embedding(vocab_size, self.embed_dim, padding_idx=pad_ix)\n",
    "    if self.freeze_embeddings:\n",
    "      self.embed_layer.weight.requires_grad = False\n",
    "\n",
    "    \"\"\" Capa Oculta\n",
    "    \"\"\"\n",
    "    full_window_size = 2 * window_size + 1\n",
    "    self.hidden_layer = nn.Sequential(\n",
    "      nn.Linear(full_window_size * self.embed_dim, self.hidden_dim), \n",
    "      nn.Tanh()\n",
    "    )\n",
    "\n",
    "    \"\"\" Caba de salida\n",
    "    \"\"\"\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    \"\"\" Probabilidades \n",
    "    \"\"\"\n",
    "    self.probabilities = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    \"\"\"\n",
    "    Sea B:= batch_size\n",
    "        L:= longitud de la ventana de la sentencia rellenada\n",
    "        D:= self.embed_dim\n",
    "        S:= self.window_size\n",
    "        H:= self.hidden_dim\n",
    "        \n",
    "    entradas: un tensor (B, L) de los indices de los tokens\n",
    "    \"\"\"\n",
    "    B, L = inputs.size()\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Entra un tensor de tipo Long (B, L) \n",
    "    Produce un tensor de tipo Long (B, L~, S)\n",
    "    \"\"\"\n",
    "    # Primero, obtiene las ventanas de palabras para cada palabra de entrada.\n",
    "    token_windows = inputs.unfold(1, 2 * self.window_size + 1, 1)\n",
    "    _, adjusted_length, _ = token_windows.size()\n",
    "\n",
    "    # Es buena idea hacer verificaciones internas del tamaño de un tensor\n",
    "    assert token_windows.size() == (B, adjusted_length, 2 * self.window_size + 1)\n",
    "\n",
    "    \"\"\"\n",
    "    Embedding.\n",
    "    Entra un torch.LongTensor de tamano (B, L~, S) \n",
    "    Produce un (B, L~, S, D) FloatTensor.\n",
    "    \"\"\"\n",
    "    embedded_windows = self.embeds(token_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Reshaping.\n",
    "    Entra un (B, L~, S, D) FloatTensor.\n",
    "    Cambia su tamano a (B, L~, S*D) FloatTensor.\n",
    "    El argumento -1  \"infiere\" ser la última dimensión segun los ejes sobrantes.\n",
    "    \"\"\"\n",
    "    embedded_windows = embedded_windows.view(B, adjusted_length, -1)\n",
    "\n",
    "    \"\"\"\n",
    "    Capa 1.\n",
    "    Entra un (B, L~, S*D) FloatTensor.\n",
    "    Cambia su tamaño a un (B, L~, H) FloatTensor\n",
    "    \"\"\"\n",
    "    layer_1 = self.hidden_layer(embedded_windows)\n",
    "\n",
    "    \"\"\"\n",
    "    Capa 2\n",
    "    Entra un (B, L~, H) FloatTensor.\n",
    "    cambia su tamano a un (B, L~, 1) FloatTensor.\n",
    "    \"\"\"\n",
    "    output = self.output_layer(layer_1)\n",
    "\n",
    "    \"\"\"\n",
    "    Softmax.\n",
    "    Entra un (B, L~, 1) FloatTensor de scores de clases no normalizados.\n",
    "    Produce un (B, L~, 1) FloatTensor de scores de clases (log-)normalizados.\n",
    "    \"\"\"\n",
    "    output = self.probabilities(output)\n",
    "    output = output.view(B, -1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aStmaQ9QskZ"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "0LbEEsyCQskZ"
   },
   "outputs": [],
   "source": [
    "# Prepara los datos\n",
    "data = list(zip(train_sentences, train_labels))\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=window_size, word_to_ix=word_to_ix)\n",
    "\n",
    "# Instancia el dataloader\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Inicializa el modelo\n",
    "# Es util colocar todos los hiperparamentros en un diccionario\n",
    "model_hyperparameters = {\n",
    "    \"batch_size\": 4,\n",
    "    \"window_size\": 2,\n",
    "    \"embed_dim\": 25,\n",
    "    \"hidden_dim\": 25,\n",
    "    \"freeze_embeddings\": False,\n",
    "}\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "model = WordWindowClassifier(model_hyperparameters, vocab_size)\n",
    "\n",
    "# define un optimizador\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Definir una función de pérdida, que calcula el binary cross entropy \n",
    "def loss_function(batch_outputs, batch_labels, batch_lengths):   \n",
    "    # calcula el loss para todo el batch\n",
    "    bceloss = nn.BCELoss()\n",
    "    loss = bceloss(batch_outputs, batch_labels.float())\n",
    "\n",
    "    # Reescala el loss. Recuerde que hemos utilizado longitudes para almacenar el\n",
    "    # número de palabras en cada muestra de entrenamiento\n",
    "    loss = loss / batch_lengths.sum().float()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Ng0M5tCeQskZ"
   },
   "outputs": [],
   "source": [
    "# Funcion que se llamara en cada epoch\n",
    "def train_epoch(loss_function, optimizer, model, loader):\n",
    "  \n",
    "  # guarda el registro del loss para cada epoch\n",
    "  total_loss = 0\n",
    "  for batch_inputs, batch_labels, batch_lengths in loader:\n",
    "    # limpia los gradientes\n",
    "    optimizer.zero_grad()\n",
    "    # corre un forward pass\n",
    "    outputs = model.forward(batch_inputs)\n",
    "    # calcula el loss para un batch\n",
    "    loss = loss_function(outputs, batch_labels, batch_lengths)\n",
    "    # Calcula los gradientes\n",
    "    loss.backward()\n",
    "    # Actualiza los parámetros\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  return total_loss\n",
    "\n",
    "\n",
    "# Función que contiene el loop principal\n",
    "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
    "\n",
    "  # Itera a traves de cada epoch y llama la funcion de train_epoch function\n",
    "  for epoch in range(num_epochs):\n",
    "    epoch_loss = train_epoch(loss_function, optimizer, model, loader)\n",
    "    if epoch % 100 == 0: print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Rbuk1pRMQska",
    "outputId": "2d873b6a-e691-4169-8448-69b6ff5bd565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5477850958704948\n",
      "0.2948554502800107\n",
      "0.1939490034710616\n",
      "0.1461947705829516\n",
      "0.07569601654540747\n",
      "0.01756217615911737\n",
      "0.005303380901750643\n",
      "-0.13612786791054532\n",
      "-0.033077325992053375\n",
      "-0.4676091106957756\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "train(loss_function, optimizer, model, loader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdLEVQ4fQska"
   },
   "source": [
    "### Validación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frase original\n",
      "El arte es una garantía de cordura.\n",
      "train sentences\n",
      "['el', 'arte', 'es', 'una', 'garantia', 'de', 'cordura.']\n",
      "train_label\n",
      "[0, 2, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "element_ = 3\n",
    "print('frase original')\n",
    "print(corpus[element_])\n",
    "print('train sentences')\n",
    "print(train_sentences[element_])\n",
    "print('train_label')\n",
    "print(train_labels[element_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1eINCypZQska"
   },
   "outputs": [],
   "source": [
    "# Creando una sentencia de prueba\n",
    "test_corpus = [corpus[element_]]\n",
    "test_sentences = [s.lower().split() for s in test_corpus]\n",
    "test_labels = [train_labels[element_]]\n",
    "\n",
    "# Crea un dataloader de prueba\n",
    "test_data = list(zip(test_sentences, test_labels))\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "window_size = 2\n",
    "collate_fn = partial(custom_collate_fn, window_size=12, word_to_ix=word_to_ix)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                           batch_size=1, \n",
    "                                           shuffle=False, \n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "l8SDV1MpQska",
    "outputId": "6cc804a9-0ab8-4acf-d4aa-db5b083d14e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2, 0, 0, 0, 0, 0]])\n",
      "tensor([[6.4885e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04,\n",
      "         6.4885e-04, 6.4885e-04, 2.6898e-03, 2.7427e-02, 1.3700e-02, 9.9952e-01,\n",
      "         1.5909e-02, 1.0681e-01, 1.2289e-02, 7.6458e-03, 5.8531e-04, 7.8226e-04,\n",
      "         5.6416e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04, 6.4885e-04,\n",
      "         6.4886e-04, 6.4885e-04, 6.4886e-04]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for test_instance, labels, _ in test_loader:\n",
    "  outputs = model.forward(test_instance)\n",
    "  print(labels)\n",
    "  print(outputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS224N PyTorch Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('nlp-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "cf856c288227c1985b5319abfa2c7eaa1df0528794ab1c4cb755b7b4904e1cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
